{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "Time: 1-1.5h\n",
    "\n",
    "Idea: Introduce a maximum easy WS scenario, people do themselves\n",
    "\n",
    "Content:\n",
    "- Labeling function output\n",
    "- Majority Vote\n",
    "- Label Model: Snorkel / smth. Newer\n",
    "- Decide if Lin. Reg / BERT / both\n",
    "- E2E model? SepLL    (if time permits only)\n",
    "\n",
    "To think about:\n",
    "- time (if there is still some remaining, spend it on some denoising method example?)\n",
    "- prepare additional files (packages, incl. wrench, instruction how to create a venv, datasets - spam, yoruba + instruction how to access wrench datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import pandas\n",
    "from snorkel.utils import probs_to_preds\n",
    "from utils import load_spam_dataset\n",
    "from wrench.dataset import load_dataset\n",
    "from wrench.endmodel import EndClassifierModel\n",
    "from wrench.labelmodel import MajorityVoting, Fable\n",
    "\n",
    "path_to_data = \"/Users/asedova/PycharmProjects/01_datasets/wrench/\"\n",
    "# os.chdir(\"wrench/spam\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T13:51:58.763337Z",
     "end_time": "2023-08-10T13:51:58.766874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/asedova/PycharmProjects/WS_tutorial/venv/bin/./python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T19:58:18.466579Z",
     "end_time": "2023-08-09T19:58:18.619408Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weak Supervision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: some intro, what is WS once again, what do we need to train a classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_raw_spam_dataset' from 'utils' (/Users/asedova/PycharmProjects/WS_tutorial/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_raw_spam_dataset\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# load the YouTube dataset\u001B[39;00m\n\u001B[1;32m      4\u001B[0m df_train, df_dev, df_test \u001B[38;5;241m=\u001B[39m load_raw_spam_dataset(load_train_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, split_dev_valid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'load_raw_spam_dataset' from 'utils' (/Users/asedova/PycharmProjects/WS_tutorial/utils.py)"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: intro to the dataset, LFs, output\n",
    "\n",
    "YouTube comments dataset:\n",
    "- HAM: comments relevant to the video (even very simple ones), or\n",
    "- SPAM: irrelevant (often trying to advertise something) or inappropriate messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T13:52:02.374441Z",
     "end_time": "2023-08-10T13:52:02.389214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             author                 date  \\\n0  Alessandro leite  2014-11-05T22:21:36   \n1      Salim Tayara  2014-11-02T14:33:30   \n2           Phuc Ly  2014-01-20T15:27:47   \n3      DropShotSk8r  2014-01-19T04:27:18   \n4            css403  2014-11-07T14:25:48   \n5      Giang Nguyen  2014-11-06T04:55:41   \n6      Caius Ballad  2014-11-13T00:58:20   \n7             Holly  2014-11-06T13:41:30   \n8         King uzzy  2014-11-07T23:19:08   \n9          iKap Taz  2014-11-08T13:34:27   \n\n                                                text  label  video  \n0  pls http://www10.vakinha.com.br/VaquinhaE.aspx...      1      1  \n1  if your like drones, plz subscribe to Kamal Ta...      1      1  \n2                     go here to check the views :3﻿      0      1  \n3            Came here to check the views, goodbye.﻿      0      1  \n4                      i am 2,126,492,636 viewer :D﻿      0      1  \n5                https://www.facebook.com/teeLaLaLa﻿      1      1  \n6  imagine if this guy put adsense on with all th...      0      1  \n7              Follow me on Twitter @mscalifornia95﻿      1      1  \n8   Can we reach 3 billion views by December 2014? ﻿      0      1  \n9  Follow 4 Follow                           @ Va...      1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>text</th>\n      <th>label</th>\n      <th>video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alessandro leite</td>\n      <td>2014-11-05T22:21:36</td>\n      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Salim Tayara</td>\n      <td>2014-11-02T14:33:30</td>\n      <td>if your like drones, plz subscribe to Kamal Ta...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Phuc Ly</td>\n      <td>2014-01-20T15:27:47</td>\n      <td>go here to check the views :3﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DropShotSk8r</td>\n      <td>2014-01-19T04:27:18</td>\n      <td>Came here to check the views, goodbye.﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>css403</td>\n      <td>2014-11-07T14:25:48</td>\n      <td>i am 2,126,492,636 viewer :D﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Giang Nguyen</td>\n      <td>2014-11-06T04:55:41</td>\n      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Caius Ballad</td>\n      <td>2014-11-13T00:58:20</td>\n      <td>imagine if this guy put adsense on with all th...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Holly</td>\n      <td>2014-11-06T13:41:30</td>\n      <td>Follow me on Twitter @mscalifornia95﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>King uzzy</td>\n      <td>2014-11-07T23:19:08</td>\n      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iKap Taz</td>\n      <td>2014-11-08T13:34:27</td>\n      <td>Follow 4 Follow                           @ Va...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "             author                 date  \\\n0  Alessandro leite  2014-11-05T22:21:36   \n1      Salim Tayara  2014-11-02T14:33:30   \n2           Phuc Ly  2014-01-20T15:27:47   \n3      DropShotSk8r  2014-01-19T04:27:18   \n4            css403  2014-11-07T14:25:48   \n5      Giang Nguyen  2014-11-06T04:55:41   \n6      Caius Ballad  2014-11-13T00:58:20   \n7             Holly  2014-11-06T13:41:30   \n8         King uzzy  2014-11-07T23:19:08   \n9          iKap Taz  2014-11-08T13:34:27   \n\n                                                text  label  video  \n0  pls http://www10.vakinha.com.br/VaquinhaE.aspx...      1      1  \n1  if your like drones, plz subscribe to Kamal Ta...      1      1  \n2                     go here to check the views :3﻿      0      1  \n3            Came here to check the views, goodbye.﻿      0      1  \n4                      i am 2,126,492,636 viewer :D﻿      0      1  \n5                https://www.facebook.com/teeLaLaLa﻿      1      1  \n6  imagine if this guy put adsense on with all th...      0      1  \n7              Follow me on Twitter @mscalifornia95﻿      1      1  \n8   Can we reach 3 billion views by December 2014? ﻿      0      1  \n9  Follow 4 Follow                           @ Va...      1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>text</th>\n      <th>label</th>\n      <th>video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alessandro leite</td>\n      <td>2014-11-05T22:21:36</td>\n      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Salim Tayara</td>\n      <td>2014-11-02T14:33:30</td>\n      <td>if your like drones, plz subscribe to Kamal Ta...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Phuc Ly</td>\n      <td>2014-01-20T15:27:47</td>\n      <td>go here to check the views :3﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DropShotSk8r</td>\n      <td>2014-01-19T04:27:18</td>\n      <td>Came here to check the views, goodbye.﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>css403</td>\n      <td>2014-11-07T14:25:48</td>\n      <td>i am 2,126,492,636 viewer :D﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Giang Nguyen</td>\n      <td>2014-11-06T04:55:41</td>\n      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Caius Ballad</td>\n      <td>2014-11-13T00:58:20</td>\n      <td>imagine if this guy put adsense on with all th...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Holly</td>\n      <td>2014-11-06T13:41:30</td>\n      <td>Follow me on Twitter @mscalifornia95﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>King uzzy</td>\n      <td>2014-11-07T23:19:08</td>\n      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iKap Taz</td>\n      <td>2014-11-08T13:34:27</td>\n      <td>Follow 4 Follow                           @ Va...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the YouTube dataset\n",
    "df_train, df_test = load_spam_dataset(load_train_labels=True)\n",
    "Y_train = df_train[\"label\"].values\n",
    "Y_test = df_test[\"label\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T21:56:46.436155Z",
     "end_time": "2023-08-09T21:56:46.488416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2550162073.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[19], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Examples of SPAM messages (label = 1):\u001B[0m\n\u001B[0m             ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_train[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-28T09:46:39.520876Z",
     "end_time": "2023-07-28T09:46:39.528756Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examples of SPAM messages (label = 1):\n",
    "- \"Please check out my vidios\"\n",
    "- \"Subscribe to me and I'll subscribe back!!!\"\n",
    "\n",
    "Examples of HAM messages (label = 0):\n",
    "- \"3:46 so cute!\"\n",
    "- \"This is a weird video.\"\n",
    "\n",
    "todo: what do we have here? text + gold labels. What if there are no gold labels?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What can be a labeling function?\n",
    "\n",
    "- Keyword searches: looking for specific words in a sentence\n",
    "- Pattern matching: looking for specific syntactical patterns\n",
    "- Third-party models: using an pre-trained model (usually a model for a different task than the one at hand)\n",
    "...\n",
    "- Crowdworker labels: treating each crowdworker as a black-box function that assigns labels to subsets of the data\n",
    "\n",
    "For detection of YouTube comments dataset: e.g. \"check out\" - a marker of a SPAM comment"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T21:04:15.007312Z",
     "end_time": "2023-08-09T21:04:15.013913Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# an example of LF based on a key word \"check out\"\n",
    "def check_out(x):\n",
    "    return 1 if \"check out\" in x.text.lower() else -1\n",
    "\n",
    "# an example of LF based on a key word \"check\"\n",
    "def check(x):\n",
    "    return 1 if \"check\" in x.text.lower() else -1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-28T09:46:40.003603Z",
     "end_time": "2023-07-28T09:46:40.010635Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: e.g., we created 10 LFs and applied them for each sentence. The result can be saved in the following format:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T22:01:26.383285Z",
     "end_time": "2023-08-09T22:01:27.414881Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                data label  \\\n0  {'text': 'pls http://www10.vakinha.com.br/Vaqu...     1   \n1  {'text': 'if your like drones, plz subscribe t...     1   \n2         {'text': 'go here to check the views :3﻿'}     0   \n3  {'text': 'Came here to check the views, goodby...     0   \n4          {'text': 'i am 2,126,492,636 viewer :D﻿'}     0   \n\n                                weak_labels  \n0   [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1]  \n1     [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]  \n2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>label</th>\n      <th>weak_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'text': 'pls http://www10.vakinha.com.br/Vaqu...</td>\n      <td>1</td>\n      <td>[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'text': 'if your like drones, plz subscribe t...</td>\n      <td>1</td>\n      <td>[-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'text': 'go here to check the views :3﻿'}</td>\n      <td>0</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'text': 'Came here to check the views, goodby...</td>\n      <td>0</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'text': 'i am 2,126,492,636 viewer :D﻿'}</td>\n      <td>0</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/Users/asedova/PycharmProjects/01_datasets/wrench/youtube/train.json\") as train_file:\n",
    "    train_data = pandas.read_json(train_file)\n",
    "print(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T22:01:08.405006Z",
     "end_time": "2023-08-09T22:01:08.413992Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: explain what are the data, labels (=still gold ones), weak_labels (=the annotations after applying LFs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T14:38:12.445819Z",
     "end_time": "2023-08-10T14:38:12.461055Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: what is majority vote?\n",
    "todo: how to get the weak labels from the wrench data to train a classifier?\n",
    "todo: example of classifier training\n",
    "todo: other labeling model (e.g. Snorkel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T13:54:51.751474Z",
     "end_time": "2023-08-10T13:54:52.177315Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to obtain weak labels?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:13.094259Z",
     "end_time": "2023-08-10T15:48:13.475728Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: different labeling functions: 1) (simple) majority vote 2) (more advanced) FABLE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:15.049170Z",
     "end_time": "2023-08-10T15:48:15.062358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                data  \\\n0  {'text': 'pls http://www10.vakinha.com.br/Vaqu...   \n1  {'text': 'if your like drones, plz subscribe t...   \n2         {'text': 'go here to check the views :3﻿'}   \n3  {'text': 'Came here to check the views, goodby...   \n4          {'text': 'i am 2,126,492,636 viewer :D﻿'}   \n\n                                weak_labels  \n0   [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1]  \n1     [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]  \n2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>weak_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'text': 'pls http://www10.vakinha.com.br/Vaqu...</td>\n      <td>[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'text': 'if your like drones, plz subscribe t...</td>\n      <td>[-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'text': 'go here to check the views :3﻿'}</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'text': 'Came here to check the views, goodby...</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'text': 'i am 2,126,492,636 viewer :D﻿'}</td>\n      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = load_dataset(\n",
    "    path_to_data,\n",
    "    \"youtube\",\n",
    "    extract_feature=True,\n",
    "    extract_fn='tfidf'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-28T09:50:56.879926Z",
     "end_time": "2023-07-28T09:50:57.125044Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Majority Vote\n",
    "(+ todo: a small description)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T21:57:30.941063Z",
     "end_time": "2023-08-09T21:57:30.953595Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# initialize and apply the majority vote\n",
    "label_model = MajorityVoting()\n",
    "label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T21:57:32.030001Z",
     "end_time": "2023-08-09T21:57:32.066429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1586 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5727d3e573546c184ceb81090fdd1c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/120 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a47f86ba32004a92ade217e2df875732"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80ab797435b74d5e997e14ba046ca839"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate labels\n",
    "soft_label_mv = label_model.predict_proba(train_data)\n",
    "hard_label_mv = probs_to_preds(soft_label_mv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:21.267450Z",
     "end_time": "2023-08-10T15:48:21.596925Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Fable\n",
    "(+ todo: a small description)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:22.789069Z",
     "end_time": "2023-08-10T15:48:22.801882Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# initialize and apply the fable model\n",
    "label_model = Fable(kernel_function=None, num_groups=3)\n",
    "label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:24.775074Z",
     "end_time": "2023-08-10T15:48:24.814988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 0, ..., 1, 1, 1])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate labels\n",
    "soft_label_fable = label_model.predict_proba(train_data)\n",
    "hard_label_fable = probs_to_preds(soft_label_mv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T15:48:26.324866Z",
     "end_time": "2023-08-10T15:48:26.358724Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to train a classifier?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'weak_labels'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wb/csjc8zl5223fy_zxm_f4yx0c0000gn/T/ipykernel_6595/3898220101.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;31m# initialize and apply the fable model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mlabel_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkernel_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_groups\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mlabel_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_valid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalid_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/WS_tutorial/wrench/labelmodel/fable.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, dataset_train, dataset_valid, y_valid, n_class, verbose, *args, **kwargs)\u001B[0m\n\u001B[1;32m    389\u001B[0m             \u001B[0mn_class\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m             \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbool\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m             \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    392\u001B[0m             **kwargs: Any):\n\u001B[0;32m--> 393\u001B[0;31m         \u001B[0mtrain_tuples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_tuples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    394\u001B[0m         \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m         \u001B[0mnan_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnan_index\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/WS_tutorial/wrench/labelmodel/fable.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(dataset)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcreate_tuples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mBaseDataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweak_labels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m     workers = np.repeat(\n\u001B[1;32m     16\u001B[0m         \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweak_labels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweak_labels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     ).reshape(len(dataset.weak_labels[0]), -1).T.reshape(-1)\n",
      "\u001B[0;32m~/PycharmProjects/WS_tutorial/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   5571\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5572\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5573\u001B[0m         ):\n\u001B[1;32m   5574\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5575\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'weak_labels'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "lr = 0.01\n",
    "\n",
    "model = EndClassifierModel(\n",
    "    batch_size=batch_size, test_batch_size=test_batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
