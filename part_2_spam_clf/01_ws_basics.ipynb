{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:01:49.724452Z",
     "start_time": "2023-09-26T15:01:49.704728Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: How to train a classifier using Weak Supervision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to train a spam detection classifier using weakly supervised data. \n",
    "\n",
    "The steps:\n",
    "- Collect training data\n",
    "- Annotate this data in a weakly supervised setting\n",
    "    - Create labeling functions\n",
    "    - *Match* the labeling functions to the data samples\n",
    "    - Aggregate the labels with different label aggregation techniques\n",
    "        - Majority Vote\n",
    "        - FABLE \n",
    "- train a logistic regression classifier using weak labels\n",
    "- train a logistic regresison classifier with SepLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:01:56.751414Z",
     "start_time": "2023-09-26T15:01:51.712762Z"
    }
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from snorkel.utils import probs_to_preds\n",
    "from utils.part_2 import load_raw_spam_dataset\n",
    "from wrench.utils import set_seed\n",
    "from wrench.endmodel import EndClassifierModel\n",
    "from wrench._logging import LoggingHandler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:03.693653Z",
     "start_time": "2023-09-26T15:02:03.650348Z"
    }
   },
   "outputs": [],
   "source": [
    "# the path to the folder where our data is stored\n",
    "\n",
    "path_to_data = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T13:52:02.389214Z",
     "start_time": "2023-08-10T13:52:02.374441Z"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use for training is Spam Detection YouTube comments dataset \n",
    "[3]. \n",
    "\n",
    "- The dataset consists of comments that YouTube users left under different videos.\n",
    "- Each sample is a comment (i.e., a word, a sentence, or a couple of sentences).\n",
    "- 1,586 train samples, 120 dev samples, 250 test samples\n",
    "- There are 2 types of samples:\n",
    "    - HAM: comments relevant to the video (even very simple ones), or\n",
    "    - SPAM: irrelevant (often trying to advertise something) or inappropriate messages\n",
    "    \n",
    "<img src=\"../img/spam_detection.png\" width=\"800\"/>\n",
    "\n",
    "**NB! Original dataset is manually labeled, but we won't use these gold labels for model training! We will use the dataset as unlabeled one (and label it in a weakly-supervised fasion).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:11.158386Z",
     "start_time": "2023-09-26T15:02:11.089005Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the YouTube dataset\n",
    "\n",
    "df_train, df_dev, df_test = load_raw_spam_dataset(load_train_labels=True)\n",
    "# Y_train = df_train[\"label\"].values\n",
    "# Y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:13.248659Z",
     "start_time": "2023-09-26T15:02:13.191473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             author                 date  \\\n0  Alessandro leite  2014-11-05T22:21:36   \n1      Salim Tayara  2014-11-02T14:33:30   \n2           Phuc Ly  2014-01-20T15:27:47   \n3      DropShotSk8r  2014-01-19T04:27:18   \n4            css403  2014-11-07T14:25:48   \n5      Giang Nguyen  2014-11-06T04:55:41   \n6      Caius Ballad  2014-11-13T00:58:20   \n7             Holly  2014-11-06T13:41:30   \n8         King uzzy  2014-11-07T23:19:08   \n9          iKap Taz  2014-11-08T13:34:27   \n\n                                                                                                                  text  \\\n0                          pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n1  if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n2                                                                                       go here to check the views :3﻿   \n3                                                                              Came here to check the views, goodbye.﻿   \n4                                                                                        i am 2,126,492,636 viewer :D﻿   \n5                                                                                  https://www.facebook.com/teeLaLaLa﻿   \n6                                  imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n7                                                                                Follow me on Twitter @mscalifornia95﻿   \n8                                                                     Can we reach 3 billion views by December 2014? ﻿   \n9                                             Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n\n   label  video  \n0      1      1  \n1      1      1  \n2      0      1  \n3      0      1  \n4      0      1  \n5      1      1  \n6      0      1  \n7      1      1  \n8      0      1  \n9      1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>text</th>\n      <th>label</th>\n      <th>video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alessandro leite</td>\n      <td>2014-11-05T22:21:36</td>\n      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Salim Tayara</td>\n      <td>2014-11-02T14:33:30</td>\n      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Phuc Ly</td>\n      <td>2014-01-20T15:27:47</td>\n      <td>go here to check the views :3﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DropShotSk8r</td>\n      <td>2014-01-19T04:27:18</td>\n      <td>Came here to check the views, goodbye.﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>css403</td>\n      <td>2014-11-07T14:25:48</td>\n      <td>i am 2,126,492,636 viewer :D﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Giang Nguyen</td>\n      <td>2014-11-06T04:55:41</td>\n      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Caius Ballad</td>\n      <td>2014-11-13T00:58:20</td>\n      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Holly</td>\n      <td>2014-11-06T13:41:30</td>\n      <td>Follow me on Twitter @mscalifornia95﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>King uzzy</td>\n      <td>2014-11-07T23:19:08</td>\n      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iKap Taz</td>\n      <td>2014-11-08T13:34:27</td>\n      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data sample in the original dataset (i.e., a YouTube comment), we know:\n",
    "- comment's author,\n",
    "- date when the corresponding comment was left,\n",
    "- text of the sample,\n",
    "- gold manual label,\n",
    "- id of the YouTube video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:17.387752Z",
     "start_time": "2023-09-26T15:02:17.327471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           author                 date  \\\n2         Phuc Ly  2014-01-20T15:27:47   \n3    DropShotSk8r  2014-01-19T04:27:18   \n4          css403  2014-11-07T14:25:48   \n6    Caius Ballad  2014-11-13T00:58:20   \n8       King uzzy  2014-11-07T23:19:08   \n10    John Plaatt  2014-11-07T22:22:29   \n11  Praise Samuel  2014-11-08T11:10:30   \n16   zhichao wang  2013-11-29T02:13:56   \n19      Tedi Foto  2014-11-08T09:33:30   \n20        Tee Tee  2014-11-07T20:16:51   \n\n                                                                                                       text  \\\n2                                                                            go here to check the views :3﻿   \n3                                                                   Came here to check the views, goodbye.﻿   \n4                                                                             i am 2,126,492,636 viewer :D﻿   \n6                       imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n8                                                          Can we reach 3 billion views by December 2014? ﻿   \n10                                                     On 0:02 u can see the camera man on his glasses....﻿   \n11  2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿   \n16            i think about 100 millions of the views come from people who only wanted to  check the views﻿   \n19                                                                                   What my gangnam style﻿   \n20                                        Loool nice song funny how no one understands (me) and we love it﻿   \n\n    label  video  \n2       0      1  \n3       0      1  \n4       0      1  \n6       0      1  \n8       0      1  \n10      0      1  \n11      0      1  \n16      0      1  \n19      0      1  \n20      0      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>text</th>\n      <th>label</th>\n      <th>video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Phuc Ly</td>\n      <td>2014-01-20T15:27:47</td>\n      <td>go here to check the views :3﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DropShotSk8r</td>\n      <td>2014-01-19T04:27:18</td>\n      <td>Came here to check the views, goodbye.﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>css403</td>\n      <td>2014-11-07T14:25:48</td>\n      <td>i am 2,126,492,636 viewer :D﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Caius Ballad</td>\n      <td>2014-11-13T00:58:20</td>\n      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>King uzzy</td>\n      <td>2014-11-07T23:19:08</td>\n      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>John Plaatt</td>\n      <td>2014-11-07T22:22:29</td>\n      <td>On 0:02 u can see the camera man on his glasses....﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Praise Samuel</td>\n      <td>2014-11-08T11:10:30</td>\n      <td>2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>zhichao wang</td>\n      <td>2013-11-29T02:13:56</td>\n      <td>i think about 100 millions of the views come from people who only wanted to  check the views﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Tedi Foto</td>\n      <td>2014-11-08T09:33:30</td>\n      <td>What my gangnam style﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Tee Tee</td>\n      <td>2014-11-07T20:16:51</td>\n      <td>Loool nice song funny how no one understands (me) and we love it﻿</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples of positive (=non-spam) samples, label id 0\n",
    "\n",
    "df_train.loc[df_train[\"label\"]==0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:22.992412Z",
     "start_time": "2023-09-26T15:02:22.942472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              author                 date  \\\n0   Alessandro leite  2014-11-05T22:21:36   \n1       Salim Tayara  2014-11-02T14:33:30   \n5       Giang Nguyen  2014-11-06T04:55:41   \n7              Holly  2014-11-06T13:41:30   \n9           iKap Taz  2014-11-08T13:34:27   \n12     Malin Linford  2014-11-05T01:13:43   \n13       Lone Twistt  2013-11-28T17:34:55   \n14         Олег Пась  2014-11-03T23:29:00   \n15           JD COKE  2014-11-08T02:24:02   \n17      Rancy Gaming  2014-11-06T09:41:07   \n\n                                                                                                                                                                                                                                                                                                                                                                          text  \\\n0                                                                                                                                                                                                                                                                                  pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n1                                                                                                                                                                                                                                                          if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n5                                                                                                                                                                                                                                                                                                                                          https://www.facebook.com/teeLaLaLa﻿   \n7                                                                                                                                                                                                                                                                                                                                        Follow me on Twitter @mscalifornia95﻿   \n9                                                                                                                                                                                                                                                                                                     Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n12                                                                                                                                                                                                                              Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿   \n13                                                                                                                                                                                          Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿   \n14                                                                                                                                                                                                                                                                                                                                                  Plizz withing my channel ﻿   \n15  It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿   \n17                                                                                                                                                                                                                                                                                             What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿   \n\n    label  video  \n0       1      1  \n1       1      1  \n5       1      1  \n7       1      1  \n9       1      1  \n12      1      1  \n13      1      1  \n14      1      1  \n15      1      1  \n17      1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>date</th>\n      <th>text</th>\n      <th>label</th>\n      <th>video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alessandro leite</td>\n      <td>2014-11-05T22:21:36</td>\n      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Salim Tayara</td>\n      <td>2014-11-02T14:33:30</td>\n      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Giang Nguyen</td>\n      <td>2014-11-06T04:55:41</td>\n      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Holly</td>\n      <td>2014-11-06T13:41:30</td>\n      <td>Follow me on Twitter @mscalifornia95﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iKap Taz</td>\n      <td>2014-11-08T13:34:27</td>\n      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Malin Linford</td>\n      <td>2014-11-05T01:13:43</td>\n      <td>Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Lone Twistt</td>\n      <td>2013-11-28T17:34:55</td>\n      <td>Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Олег Пась</td>\n      <td>2014-11-03T23:29:00</td>\n      <td>Plizz withing my channel ﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>JD COKE</td>\n      <td>2014-11-08T02:24:02</td>\n      <td>It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Rancy Gaming</td>\n      <td>2014-11-06T09:41:07</td>\n      <td>What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples of negative (=spam) samples, label id 0\n",
    "\n",
    "df_train.loc[df_train[\"label\"]==1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:02:32.877844Z",
     "start_time": "2023-09-26T15:02:32.826236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n0                                                                                                                                                                                                                                                                                                                                   pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n1                                                                                                                                                                                                                                                                                                           if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n2                                                                                                                                                                                                                                                                                                                                                                                                go here to check the views :3﻿   \n3                                                                                                                                                                                                                                                                                                                                                                                       Came here to check the views, goodbye.﻿   \n4                                                                                                                                                                                                                                                                                                                                                                                                 i am 2,126,492,636 viewer :D﻿   \n5                                                                                                                                                                                                                                                                                                                                                                                           https://www.facebook.com/teeLaLaLa﻿   \n6                                                                                                                                                                                                                                                                                                                                           imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n7                                                                                                                                                                                                                                                                                                                                                                                         Follow me on Twitter @mscalifornia95﻿   \n8                                                                                                                                                                                                                                                                                                                                                                              Can we reach 3 billion views by December 2014? ﻿   \n9                                                                                                                                                                                                                                                                                                                                                      Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n10                                                                                                                                                                                                                                                                                                                                                                         On 0:02 u can see the camera man on his glasses....﻿   \n11                                                                                                                                                                                                                                                                                                                      2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿   \n12                                                                                                                                                                                                                                                                               Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿   \n13                                                                                                                                                                                                                                           Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿   \n14                                                                                                                                                                                                                                                                                                                                                                                                   Plizz withing my channel ﻿   \n15                                                   It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿   \n16                                                                                                                                                                                                                                                                                                                                i think about 100 millions of the views come from people who only wanted to  check the views﻿   \n17                                                                                                                                                                                                                                                                                                                                              What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿   \n18  https://www.facebook.com/SchoolGeniusNITS/photos/ms.c.eJw9kVkOxDAMQm808h5z~;4sNjqP~_tHqBEuM69AQUp1Ih~_fPHgk5zLLsVdQv0ZUf0MB~;LnUJ~;ufTH4YoKfRxYts2zvrrp6qGtw67y~;L551h~;f7~_vlcZzRG8vGCTlPSD9ONGeWhj8~_GIbu~;S3lzMvY~;IQ2~;TwSfzz9WHn7JUSvHufpglQRZczl05fNPhaGeVb3x8yDmC6X~_~;jTcjnMho~;vfXWCjZyvWObihrnGx2ocjnG2PG1EvHXzyjD~_o3h~_RY6f57sPrnD2xV~;~_BzszZ~;8~-.bps.a.390875584405933/391725794320912/?type=1&amp;theater ﻿   \n19                                                                                                                                                                                                                                                                                                                                                                                                       What my gangnam style﻿   \n\n    label  \n0       1  \n1       1  \n2       0  \n3       0  \n4       0  \n5       1  \n6       0  \n7       1  \n8       0  \n9       1  \n10      0  \n11      0  \n12      1  \n13      1  \n14      1  \n15      1  \n16      0  \n17      1  \n18      1  \n19      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>go here to check the views :3﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Came here to check the views, goodbye.﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am 2,126,492,636 viewer :D﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Follow me on Twitter @mscalifornia95﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>On 0:02 u can see the camera man on his glasses....﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Plizz withing my channel ﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>i think about 100 millions of the views come from people who only wanted to  check the views﻿</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>https://www.facebook.com/SchoolGeniusNITS/photos/ms.c.eJw9kVkOxDAMQm808h5z~;4sNjqP~_tHqBEuM69AQUp1Ih~_fPHgk5zLLsVdQv0ZUf0MB~;LnUJ~;ufTH4YoKfRxYts2zvrrp6qGtw67y~;L551h~;f7~_vlcZzRG8vGCTlPSD9ONGeWhj8~_GIbu~;S3lzMvY~;IQ2~;TwSfzz9WHn7JUSvHufpglQRZczl05fNPhaGeVb3x8yDmC6X~_~;jTcjnMho~;vfXWCjZyvWObihrnGx2ocjnG2PG1EvHXzyjD~_o3h~_RY6f57sPrnD2xV~;~_BzszZ~;8~-.bps.a.390875584405933/391725794320912/?type=1&amp;amp;theater ﻿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>What my gangnam style﻿</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"text\", \"label\"]][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to start weak supervision! So, let's imagin the gold labels disappeared... \n",
    "\n",
    "<img src=\"../img/poof.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here we are: there is some data we want to use for classifier training, but we don't have any labels and capacity/time/money/... for hiring annotators.\n",
    "\n",
    "But we can label this data with **weak supervision** :)\n",
    "\n",
    "<img src=\"../img/rainbow.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak Supervision\n",
    "\n",
    "A brief reminder how weak supervision works:\n",
    "1. We come up with some heuristic rules and transform these rules into labeling functions.\n",
    "2. We apply these labeling functions to the data and obtain weak labels.\n",
    "3. We use this weak labels to train a classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: let's have a closer look at the samples and answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T21:04:15.013913Z",
     "start_time": "2023-08-09T21:04:15.007312Z"
    }
   },
   "source": [
    "*What labeling functions do you think are productive and useful to annotate the YouTube spam dataset?* \n",
    "\n",
    "*What rules might help to distinguish between spam and not-spam YouTube comments?*\n",
    "\n",
    "*What patterns are typical for spam YouTube comments? for non-spam comments?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules: \n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "4. ...\n",
    "5. ...\n",
    "6. ...\n",
    "7. ...\n",
    "8. ...\n",
    "9. ...\n",
    "10. ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My examples of rules: \n",
    "- \"check\"/\"check out\": if there is a collocation \"check out\" in the comment, most probably this comment is spam (and the comment author is promoting his/her channel)\n",
    "- \"subscribe\": same\n",
    "- \"my\": same\n",
    "- ...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can be a rule?\n",
    "\n",
    "- Keyword searches: looking for specific words in a sentence\n",
    "- Pattern matching: looking for specific syntactical patterns\n",
    "- Third-party models: using an pre-trained model (usually a model for a different task than the one at hand)\n",
    "- ...\n",
    "- Crowdworker labels: treating each crowdworker as a black-box function that assigns labels to subsets of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules into labeling functions\n",
    "\n",
    "After we collected some rules, we transform them into labeling functions that could *label* the data sample - that is, assign it to one or another class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:03:42.646301Z",
     "start_time": "2023-09-26T15:03:42.601556Z"
    }
   },
   "outputs": [],
   "source": [
    "# an example of LF based on a keyword \"check out\"\n",
    "\n",
    "def check_out(x):\n",
    "    return 1 if \"check out\" in x.text.lower() else -1\n",
    "\n",
    "# meaning the sample will be assigned to class 1 (=SPAM) if there is a \"check out\" expression in the comment, \n",
    "# otherwise to class 0 (=non-SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:03:44.342713Z",
     "start_time": "2023-09-26T15:03:44.297614Z"
    }
   },
   "outputs": [],
   "source": [
    "# an example of LF based on a key word \"please\"\n",
    "\n",
    "def check(x):\n",
    "    return 1 if \"please\" in x.text.lower() else -1\n",
    "\n",
    "# meaning the sample will be assigned to class 1 (=SPAM) if there is a \"please\" expression in the comment, \n",
    "# otherwise to class 0 (=non-SPAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T22:01:27.414881Z",
     "start_time": "2023-08-09T22:01:26.383285Z"
    }
   },
   "source": [
    "### Labeling functions we are going to use\n",
    "\n",
    "In this tutorial, we are going to use the labeling functions created by [Snorkel team](https://github.com/snorkel-team/snorkel-tutorials/blob/master/spam/01_spam_tutorial.ipynb), which are: \n",
    "\n",
    "\n",
    "1. keyword **\"my\"** (to detect spam comments like \"my channel\", \"my video\", etc)\n",
    "2. keyword **\"subscribe\"** (to detect spam comments that ask users to subscribe to some channel)\n",
    "3. keyword **\"http\"** (to detect spam comments that link to other channels)\n",
    "4. keyword **\"please\"/\"plz\"** (to detect spam comments that make requests rather than commenting)\n",
    "5. keyword **\"song\"** (to detect non-spam comments that actually talk about the video's content)\n",
    "6. regex **\"check_out\"** (to detect spam comments like \"check out this channel\", etc)\n",
    "7. **short comment** (non-spam comments are often short, such as 'cool video!')\n",
    "8. **mentioning specific people** and are **short** (using SpaCy library; non-spam comments usually mention some people)\n",
    "9. **polarity** (using TextBlob library; if polarity > 0.9, it is most probably a non-spam message)\n",
    "10. **subjectivity** (using TextBlob library; if subjectivity >= 0.5, it is most probably a non-spam message)\n",
    "\n",
    "(We are not going into details of the labeling process here now - you will hear more about it from my colleagues later). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed data\n",
    "\n",
    "The resulted annotations can be saved in the following format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:03:54.498334Z",
     "start_time": "2023-09-26T15:03:54.441446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n 'label': 1,\n 'weak_labels': [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/youtube/train.json\") as train_file:\n",
    "    train_data = json.load(train_file)\n",
    "train_data[\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T14:38:12.461055Z",
     "start_time": "2023-08-10T14:38:12.445819Z"
    }
   },
   "source": [
    "The structure of the processed data is the following: \n",
    "- data.text: the text of the sample\n",
    "- label: gold label obtained by manual annotation\n",
    "- weak_labels: the results of annotation by labeling functions. \n",
    "    - -1: the corresponding labeling function did not match\n",
    "    - 0: the labeling function matched and assigned this sample to class 0 (non-spam class in our case)\n",
    "    - 1: the labeling function matched and assigned this sample to class 1 (spam class in our case)\n",
    "\n",
    "So, for the sample #1:\n",
    "(*if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff*)\n",
    "\n",
    "- labeling functions 1, 3, 5, 6, 7, 8, 9 did not match\n",
    "- labeling functions 2 (a key word *subscribe*) & 4 (a key word *plz*) matched and assigned this sample to the class 1\n",
    "- labeling function 10 (subjectivity score > 0.5) matched and assigned this sample to the class 0\n",
    "\n",
    "**Next step: how to turn these annotations into weak labels to train a classifier with them?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:48:13.475728Z",
     "start_time": "2023-08-10T15:48:13.094259Z"
    }
   },
   "source": [
    "## Weak labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:48:15.062358Z",
     "start_time": "2023-08-10T15:48:15.049170Z"
    }
   },
   "source": [
    "There are different *label models* that calculate the weak labels based on labeling functions annotations. In this tutorial, we are going to try two of them: \n",
    "\n",
    "- **Majority Vote** (intuitive and straightforward)\n",
    "- **FABLE** [1] (most recent and well-performing)\n",
    "\n",
    "For label calculation and model training we will use a weakly supervised framework called [Wrench](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiRmYabjOGAAxW1h_0HHQt3COQQFnoECA4QAQ&url=https%3A%2F%2Fgithub.com%2FJieyuZ2%2Fwrench&usg=AOvVaw3EWVM0icLVHENbUv51USa_&opi=89978449) [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrench dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we transform our data into a Wrench-specific dataset.\n",
    "\n",
    "We can encode the data with TF-IDF features... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:03:57.629745Z",
     "start_time": "2023-09-26T15:03:57.355750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:57 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1586 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f9206ce93d44ade8e65207eb674712b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:57 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/120 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e4da624735e43d1a4aac8c503cfdfcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:57 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "682592746cae45709c37ce4ba2ac7e14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF-IDF features\n",
    "\n",
    "from wrench.dataset import load_dataset\n",
    "\n",
    "train_data_tfidf, valid_data_tfidf, test_data_tfidf = load_dataset(\n",
    "    path_to_data,     # path to the folder where the dataset is stored\n",
    "    \"youtube\",         # name of the dataset\n",
    "    extract_feature=True,      # we want to encode out data ...\n",
    "    extract_fn='tfidf'        # ... with TF-IDF features (other predefined options are 'sentence_transformer', 'bert')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or with BERT features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.461548Z",
     "start_time": "2023-09-26T15:03:59.660186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:59 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1586 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4d6a351c0344fd1a5c541a79b444dc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:59 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/120 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c16b7c4ea191426185e1a78ebc4d7c81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:03:59 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8a1046d78484283bde8a4a10c3f8953"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e13151c0f62b4691b9b67e949011f581"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33f8d9a19e2e4bb0b7f1b419c33c9f29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82768217440443e3920183e33d594f2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c22de50cb3b0418b989aa0b0e00043a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46238201026a4d45914f46f4a7d75f54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1586 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7416260d22a44266bdc93fd90517d9f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:07:04 - saving features into data/youtube/train_bert.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/120 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "377af89387ef4cee8b833a34faf99def"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:07:20 - saving features into data/youtube/valid_bert.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d14c6e934caa412eb48de064eca5b466"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:07:52 - saving features into data/youtube/test_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Bert features\n",
    "\n",
    "train_data, valid_data, test_data = load_dataset(\n",
    "    path_to_data,       # path to the folder where the dataset is stored\n",
    "    \"youtube\",    # name of the dataset\n",
    "    extract_feature=True,      # we want to encode out data ...\n",
    "    extract_fn='bert',        # ... with bert embeddings\n",
    "    model_name='bert-base-cased',      # the name of the bert model\n",
    "    cache_name='bert'     # load it from cache if there are cached files \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look what's inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.551687Z",
     "start_time": "2023-09-26T15:07:52.455772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<wrench.dataset.dataset.TextDataset at 0x7fc1aa0ca250>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the format of the train_data, valida_data, and test_data now is: wrench.dataset.dataset.TextDataset\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.628013Z",
     "start_time": "2023-09-26T15:07:52.545875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many classes are there in the dataset?\n",
    "\n",
    "train_data.n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.651490Z",
     "start_time": "2023-09-26T15:07:52.590584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many labeling functions are there in the dataset?\n",
    "\n",
    "train_data.n_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.713799Z",
     "start_time": "2023-09-26T15:07:52.633923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'HAM', 1: 'SPAM'}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the class_id to class correspondence?\n",
    "\n",
    "train_data.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.761577Z",
     "start_time": "2023-09-26T15:07:52.686981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': 'pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al\\ufeff'},\n {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n {'text': 'go here to check the views :3\\ufeff'},\n {'text': 'Came here to check the views, goodbye.\\ufeff'},\n {'text': 'i am 2,126,492,636 viewer :D\\ufeff'},\n {'text': 'https://www.facebook.com/teeLaLaLa\\ufeff'},\n {'text': 'imagine if this guy put adsense on with all these views... u could pay ur  morgage\\ufeff'},\n {'text': 'Follow me on Twitter @mscalifornia95\\ufeff'},\n {'text': 'Can we reach 3 billion views by December 2014? \\ufeff'},\n {'text': 'Follow 4 Follow                           @ VaahidMustafic Like 4 Like \\ufeff'}]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do the samples look like?\n",
    "\n",
    "train_data.examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.782930Z",
     "start_time": "2023-09-26T15:07:52.730593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-0.76088464,  0.42927504,  0.99990165, ...,  0.99997175,\n        -0.75150317,  0.9910971 ],\n       [-0.7922811 ,  0.47435868,  0.9999021 , ...,  0.9999663 ,\n        -0.75558734,  0.9860616 ],\n       [-0.71461105,  0.4088342 ,  0.9997614 , ...,  0.9999327 ,\n        -0.5964782 ,  0.98014975],\n       ...,\n       [-0.7311086 ,  0.40834078,  0.9998686 , ...,  0.99996996,\n        -0.6895463 ,  0.9860986 ],\n       [-0.60676616,  0.482777  ,  0.99963987, ...,  0.9999085 ,\n        -0.89470583,  0.9794597 ],\n       [-0.7177586 ,  0.4904495 ,  0.9998655 , ...,  0.999958  ,\n        -0.82362634,  0.9884726 ]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do the encoded samples look like?\n",
    "\n",
    "print(type(train_data.features))\n",
    "train_data.features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.859104Z",
     "start_time": "2023-09-26T15:07:52.781222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the weak annotations produced by labeling functions?\n",
    "\n",
    "train_data.weak_labels[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T21:57:30.953595Z",
     "start_time": "2023-08-09T21:57:30.941063Z"
    }
   },
   "source": [
    "### Majority Vote\n",
    "\n",
    "The simplest and most straightforward method to calculate labels from the noisy annotations is **majority voting** - a decision-making method where the option with the most votes is chosen. It's like asking a group of people to pick a movie, and the one that gets the most hands raised wins. \n",
    "\n",
    "In our case, each labeling function produces a *vote*; the most voted class is selected as a sample label. All ties are broken randomly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:  write your own majority vote function\n",
    "- Input: the weak annotations produced by labeling functions (stored in weak_labels field of wrench dataset objects)\n",
    "- Output: labels\n",
    "\n",
    "Before you start programming, think about possible bottlenecks: \n",
    "- what if a sample obtains equal amount of votes for some class?\n",
    "- what if there are no votes for a sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.873939Z",
     "start_time": "2023-09-26T15:07:52.824724Z"
    }
   },
   "outputs": [],
   "source": [
    "def majority_vote(weak_annotations):\n",
    "    # calculate labels with majority vote \n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:53.382299Z",
     "start_time": "2023-09-26T15:07:52.869667Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m labels_mv \u001B[38;5;241m=\u001B[39m \u001B[43mmajority_vote\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweak_labels\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[21], line 4\u001B[0m, in \u001B[0;36mmajority_vote\u001B[0;34m(weak_annotations)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmajority_vote\u001B[39m(weak_annotations):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# calculate labels with majority vote \u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlabels\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "labels_mv = majority_vote(train_data.weak_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ready solution to aggregate the weak labels with majority vote is already included to the Wrench framework:`MajorityVoting` label model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:14.170066Z",
     "start_time": "2023-09-26T15:08:07.434101Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize and fit the majority vote label model from the Wrench framework\n",
    "\n",
    "from wrench.labelmodel import MajorityVoting\n",
    "\n",
    "label_model = MajorityVoting()\n",
    "label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:20.979011Z",
     "start_time": "2023-09-26T15:08:20.897840Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate weak labels \n",
    "\n",
    "soft_label_mv = label_model.predict_proba(train_data)    # soft label as probabilities across all classes\n",
    "hard_label_mv = probs_to_preds(soft_label_mv)               # hard labels as the most probable classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 sentences, their weak annotations, and the weak labels obtained with majority voting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:24.167642Z",
     "start_time": "2023-09-26T15:08:24.112139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': 'pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al\\ufeff'},\n {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n {'text': 'go here to check the views :3\\ufeff'},\n {'text': 'Came here to check the views, goodbye.\\ufeff'},\n {'text': 'i am 2,126,492,636 viewer :D\\ufeff'},\n {'text': 'https://www.facebook.com/teeLaLaLa\\ufeff'},\n {'text': 'imagine if this guy put adsense on with all these views... u could pay ur  morgage\\ufeff'},\n {'text': 'Follow me on Twitter @mscalifornia95\\ufeff'},\n {'text': 'Can we reach 3 billion views by December 2014? \\ufeff'},\n {'text': 'Follow 4 Follow                           @ VaahidMustafic Like 4 Like \\ufeff'}]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:27.263925Z",
     "start_time": "2023-09-26T15:08:27.207178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1],\n [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, 1, -1, -1, -1, 0, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.weak_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:29.585852Z",
     "start_time": "2023-09-26T15:08:29.447845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 1.        ],\n       [0.33333333, 0.66666667],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ],\n       [0.5       , 0.5       ]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_label_mv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:32.403012Z",
     "start_time": "2023-09-26T15:08:32.344713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 0, 1, 0, 0, 0, 0, 1, 1])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_label_mv[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FABLE \n",
    "\n",
    "Fable [1] is a label model where noisy labels are inferred leveraging the instance features and the mixture coefficients of the EBCC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:06.230196Z",
     "start_time": "2023-09-26T15:10:02.434766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values included: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:03<58:55,  3.54s/iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize and apply the fable model\n",
    "\n",
    "from wrench.labelmodel import Fable\n",
    "\n",
    "label_model = Fable(kernel_function=None, num_groups=3)\n",
    "_ = label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:13.120855Z",
     "start_time": "2023-09-26T15:10:09.497628Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:03<55:59,  3.36s/iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate labels\n",
    "soft_label_fable = label_model.predict_proba(train_data)\n",
    "hard_label_fable = probs_to_preds(soft_label_fable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:16.193173Z",
     "start_time": "2023-09-26T15:10:16.134392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.46044647, 0.53955353],\n       [0.06476171, 0.93523829],\n       [0.60620533, 0.39379467],\n       [0.48714576, 0.51285424],\n       [0.57592072, 0.42407928],\n       [0.89144155, 0.10855845],\n       [0.51231028, 0.48768972],\n       [0.56332977, 0.43667023],\n       [0.50941031, 0.49058969],\n       [0.52484199, 0.47515801]])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_label_fable[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:18.034452Z",
     "start_time": "2023-09-26T15:10:17.979782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_label_fable[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:20.555067Z",
     "start_time": "2023-09-26T15:10:20.490550Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with majorty vote hard labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:27.927925Z",
     "start_time": "2023-09-26T15:10:22.078808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.908"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# initialize a classifier\n",
    "model = EndClassifierModel(\n",
    "    batch_size=batch_size, test_batch_size=test_batch_size\n",
    ")\n",
    "\n",
    "# fit it on the training data + majority vote hard labels\n",
    "model.fit(\n",
    "    dataset_train=train_data, \n",
    "    y_train=hard_label_mv, \n",
    "    dataset_valid=valid_data, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# test on the test set\n",
    "model.test(dataset=test_data, metric_fn=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with FABLE hard labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:32.400286Z",
     "start_time": "2023-09-26T15:10:27.930583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.856"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# initialize a classifier\n",
    "model = EndClassifierModel(\n",
    "    batch_size=batch_size, test_batch_size=test_batch_size\n",
    ")\n",
    "\n",
    "# fit it \n",
    "model.fit(\n",
    "    dataset_train=train_data, \n",
    "    y_train=hard_label_fable, \n",
    "    dataset_valid=valid_data,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# test on the test set\n",
    "model.test(dataset=test_data, metric_fn=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-2-End training with SepLL\n",
    "\n",
    "In the following, we use a state-of-the-art method called SepLL [4] to train a classifier with weak labels. During training, LF matches are the only training signal, and prediction is then later made from a latent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:12:00.176454Z",
     "start_time": "2023-09-26T15:11:29.522834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:11:29 - \n",
      "==========[hyper parameters]==========\n",
      "{\n",
      "    \"batch_size\": 32,\n",
      "    \"real_batch_size\": 16,\n",
      "    \"test_batch_size\": 32,\n",
      "    \"n_steps\": 10000,\n",
      "    \"grad_norm\": -1,\n",
      "    \"use_lr_scheduler\": false,\n",
      "    \"binary_mode\": false\n",
      "}\n",
      "==========[optimizer config]==========\n",
      "{\n",
      "    \"name\": \"Adam\",\n",
      "    \"paras\": {\n",
      "        \"lr\": 0.001,\n",
      "        \"weight_decay\": 0.0\n",
      "    }\n",
      "}\n",
      "==========[backbone config]==========\n",
      "{\n",
      "    \"name\": \"MLP\",\n",
      "    \"paras\": {\n",
      "        \"hidden_size\": 100,\n",
      "        \"dropout\": 0.0,\n",
      "        \"model_name\": \"roberta-base\"\n",
      "    }\n",
      "}\n",
      "==========[label model_config config]==========\n",
      "{\n",
      "    \"name\": \"MajorityVoting\",\n",
      "    \"paras\": {}\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andst/projects/WS_tutorial/wrench/dataset/utils.py:43: UserWarning: No unlabeled data found! Use full dataset us unlabeled dataset\n",
      "  warnings.warn('No unlabeled data found! Use full dataset us unlabeled dataset')\n",
      "/Users/andst/projects/WS_tutorial/wrench/classification/sepll.py:239: RuntimeWarning: invalid value encountered in true_divide\n",
      "  labeled_dataset.weak_labels / labeled_dataset.weak_labels.sum(axis=1, keepdims=True)\n",
      "/Users/andst/projects/WS_tutorial/wrench/classification/sepll.py:243: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dataset_valid.weak_labels / dataset_valid.weak_labels.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[TRAIN] SepLL:   0%|                                                                                          …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16dff6c211004d1a92883183f49721d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-26 17:12:00 - [INFO] early stop @ step 3000!\n",
      "2023-09-26 17:12:00 - SepLL test acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "from wrench.classification.sepll import SepLL\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "bert_model_name = 'roberta-base'\n",
    "\n",
    "#### Initialize SepLL\n",
    "model = SepLL(\n",
    "    batch_size=batch_size,\n",
    "    test_batch_size=test_batch_size,\n",
    "    backbone='MLP',\n",
    "    backbone_model_name=bert_model_name,\n",
    "    # \n",
    "    # SepLL specific\n",
    "    add_unlabeled=False,\n",
    "    class_noise=0.0,\n",
    "    lf_l2_regularization=0.05,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    dataset_train=train_data,\n",
    "    dataset_valid=valid_data,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "acc = model.test(test_data, 'acc')\n",
    "\n",
    "logger.info(f'SepLL test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPU training\n",
    "\n",
    "In case your environment has a GPU available, it is also possible to make full use of the strength of SepLL."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wrench.classification.sepll import SepLL\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "bert_model_name = 'roberta-base'\n",
    "\n",
    "#### Initialize SepLL\n",
    "model = SepLL(\n",
    "    batch_size=batch_size,\n",
    "    real_batch_size=batch_size,\n",
    "    test_batch_size=test_batch_size,\n",
    "    # BERT specific parameters\n",
    "    backbone='BERT',\n",
    "    backbone_model_name=bert_model_name,\n",
    "    optimizer='Adam',\n",
    "    optimizer_lr=1e-4,\n",
    "    optimizer_weight_decay=0.0,\n",
    "    \n",
    "    # SepLL specific\n",
    "    add_unlabeled=False,\n",
    "    class_noise=0.0,\n",
    "    lf_l2_regularization=0.05,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    dataset_train=train_data,\n",
    "    dataset_valid=valid_data,\n",
    "    metric='acc',\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = model.test(test_data, 'acc')\n",
    "\n",
    "logger.info(f'SepLL test acc: {acc}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Zhang et al. 2023. Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision. https://arxiv.org/abs/2210.02724 \n",
    "2. Zhang et al. 2021 WRENCH: A Comprehensive Benchmark for Weak Supervision. https://arxiv.org/abs/2109.11377\n",
    "3. Alberto TC et al.  2015. Tubespam: Comment Spam Filtering on Youtube. https://ieeexplore.ieee.org/document/7424299\n",
    "4. Stephan et al. 2022. SepLL: Separating Latent Class Labels from Weak Supervision Noise. https://arxiv.org/abs/2210.13898\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
