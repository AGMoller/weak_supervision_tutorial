{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:06:49.697254Z",
     "start_time": "2023-09-29T07:06:49.666342Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: How to train a classifier using Weak Supervision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to train a spam detection classifier using weakly supervised data. \n",
    "\n",
    "The steps:\n",
    "- Collect training data\n",
    "- Annotate this data in a weakly supervised setting\n",
    "    - Create labeling functions\n",
    "    - *Match* the labeling functions to the data samples\n",
    "    - Aggregate the labels with different label aggregation techniques\n",
    "        - Majority Vote\n",
    "        - FABLE \n",
    "- train a logistic regression classifier using weak labels\n",
    "- train a logistic regresison classifier with SepLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:51:21.892402Z",
     "start_time": "2023-09-29T07:51:21.606689Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "from wrench.utils import set_seed\n",
    "from wrench.endmodel import EndClassifierModel\n",
    "from wrench._logging import LoggingHandler\n",
    "\n",
    "\n",
    "from snorkel.utils import probs_to_preds\n",
    "from utils import load_raw_spam_dataset\n",
    "\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:06:54.468974Z",
     "start_time": "2023-09-29T07:06:54.421793Z"
    }
   },
   "outputs": [],
   "source": [
    "# the path to the folder where our data is stored\n",
    "\n",
    "path_to_data = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T13:52:02.389214Z",
     "start_time": "2023-08-10T13:52:02.374441Z"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use for training is Spam Detection YouTube comments dataset \n",
    "[3]. \n",
    "\n",
    "- The dataset consists of comments that YouTube users left under different videos.\n",
    "- Each sample is a comment (i.e., a word, a sentence, or a couple of sentences).\n",
    "- 1,586 train samples, 120 dev samples, 250 test samples\n",
    "- There are 2 types of samples:\n",
    "    - HAM: comments relevant to the video (even very simple ones), or\n",
    "    - SPAM: irrelevant (often trying to advertise something) or inappropriate messages\n",
    "    \n",
    "<img src=\"../img/spam_detection.png\" width=\"800\"/>\n",
    "\n",
    "**NB! Original dataset is manually labeled, but we won't use these gold labels for model training! We will use the dataset as unlabeled one (and label it in a weakly-supervised fasion).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:06:56.271834Z",
     "start_time": "2023-09-29T07:06:56.174522Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the YouTube dataset\n",
    "\n",
    "df_train, df_dev, df_test = load_raw_spam_dataset(load_train_labels=True)\n",
    "# Y_train = df_train[\"label\"].values\n",
    "# Y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:06:59.329219Z",
     "start_time": "2023-09-29T07:06:59.263980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alessandro leite</td>\n",
       "      <td>2014-11-05T22:21:36</td>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salim Tayara</td>\n",
       "      <td>2014-11-02T14:33:30</td>\n",
       "      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phuc Ly</td>\n",
       "      <td>2014-01-20T15:27:47</td>\n",
       "      <td>go here to check the views :3﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DropShotSk8r</td>\n",
       "      <td>2014-01-19T04:27:18</td>\n",
       "      <td>Came here to check the views, goodbye.﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>css403</td>\n",
       "      <td>2014-11-07T14:25:48</td>\n",
       "      <td>i am 2,126,492,636 viewer :D﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Giang Nguyen</td>\n",
       "      <td>2014-11-06T04:55:41</td>\n",
       "      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Caius Ballad</td>\n",
       "      <td>2014-11-13T00:58:20</td>\n",
       "      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Holly</td>\n",
       "      <td>2014-11-06T13:41:30</td>\n",
       "      <td>Follow me on Twitter @mscalifornia95﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>King uzzy</td>\n",
       "      <td>2014-11-07T23:19:08</td>\n",
       "      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iKap Taz</td>\n",
       "      <td>2014-11-08T13:34:27</td>\n",
       "      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                 date  \\\n",
       "0  Alessandro leite  2014-11-05T22:21:36   \n",
       "1      Salim Tayara  2014-11-02T14:33:30   \n",
       "2           Phuc Ly  2014-01-20T15:27:47   \n",
       "3      DropShotSk8r  2014-01-19T04:27:18   \n",
       "4            css403  2014-11-07T14:25:48   \n",
       "5      Giang Nguyen  2014-11-06T04:55:41   \n",
       "6      Caius Ballad  2014-11-13T00:58:20   \n",
       "7             Holly  2014-11-06T13:41:30   \n",
       "8         King uzzy  2014-11-07T23:19:08   \n",
       "9          iKap Taz  2014-11-08T13:34:27   \n",
       "\n",
       "                                                                                                                  text  \\\n",
       "0                          pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n",
       "1  if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n",
       "2                                                                                       go here to check the views :3﻿   \n",
       "3                                                                              Came here to check the views, goodbye.﻿   \n",
       "4                                                                                        i am 2,126,492,636 viewer :D﻿   \n",
       "5                                                                                  https://www.facebook.com/teeLaLaLa﻿   \n",
       "6                                  imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n",
       "7                                                                                Follow me on Twitter @mscalifornia95﻿   \n",
       "8                                                                     Can we reach 3 billion views by December 2014? ﻿   \n",
       "9                                             Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n",
       "\n",
       "   label  video  \n",
       "0      1      1  \n",
       "1      1      1  \n",
       "2      0      1  \n",
       "3      0      1  \n",
       "4      0      1  \n",
       "5      1      1  \n",
       "6      0      1  \n",
       "7      1      1  \n",
       "8      0      1  \n",
       "9      1      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data sample in the original dataset (i.e., a YouTube comment), we know:\n",
    "- comment's author,\n",
    "- date when the corresponding comment was left,\n",
    "- text of the sample,\n",
    "- gold manual label,\n",
    "- id of the YouTube video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:06.649247Z",
     "start_time": "2023-09-29T07:07:06.585409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phuc Ly</td>\n",
       "      <td>2014-01-20T15:27:47</td>\n",
       "      <td>go here to check the views :3﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DropShotSk8r</td>\n",
       "      <td>2014-01-19T04:27:18</td>\n",
       "      <td>Came here to check the views, goodbye.﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>css403</td>\n",
       "      <td>2014-11-07T14:25:48</td>\n",
       "      <td>i am 2,126,492,636 viewer :D﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Caius Ballad</td>\n",
       "      <td>2014-11-13T00:58:20</td>\n",
       "      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>King uzzy</td>\n",
       "      <td>2014-11-07T23:19:08</td>\n",
       "      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>John Plaatt</td>\n",
       "      <td>2014-11-07T22:22:29</td>\n",
       "      <td>On 0:02 u can see the camera man on his glasses....﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Praise Samuel</td>\n",
       "      <td>2014-11-08T11:10:30</td>\n",
       "      <td>2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zhichao wang</td>\n",
       "      <td>2013-11-29T02:13:56</td>\n",
       "      <td>i think about 100 millions of the views come from people who only wanted to  check the views﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tedi Foto</td>\n",
       "      <td>2014-11-08T09:33:30</td>\n",
       "      <td>What my gangnam style﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tee Tee</td>\n",
       "      <td>2014-11-07T20:16:51</td>\n",
       "      <td>Loool nice song funny how no one understands (me) and we love it﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                 date  \\\n",
       "2         Phuc Ly  2014-01-20T15:27:47   \n",
       "3    DropShotSk8r  2014-01-19T04:27:18   \n",
       "4          css403  2014-11-07T14:25:48   \n",
       "6    Caius Ballad  2014-11-13T00:58:20   \n",
       "8       King uzzy  2014-11-07T23:19:08   \n",
       "10    John Plaatt  2014-11-07T22:22:29   \n",
       "11  Praise Samuel  2014-11-08T11:10:30   \n",
       "16   zhichao wang  2013-11-29T02:13:56   \n",
       "19      Tedi Foto  2014-11-08T09:33:30   \n",
       "20        Tee Tee  2014-11-07T20:16:51   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "2                                                                            go here to check the views :3﻿   \n",
       "3                                                                   Came here to check the views, goodbye.﻿   \n",
       "4                                                                             i am 2,126,492,636 viewer :D﻿   \n",
       "6                       imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n",
       "8                                                          Can we reach 3 billion views by December 2014? ﻿   \n",
       "10                                                     On 0:02 u can see the camera man on his glasses....﻿   \n",
       "11  2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿   \n",
       "16            i think about 100 millions of the views come from people who only wanted to  check the views﻿   \n",
       "19                                                                                   What my gangnam style﻿   \n",
       "20                                        Loool nice song funny how no one understands (me) and we love it﻿   \n",
       "\n",
       "    label  video  \n",
       "2       0      1  \n",
       "3       0      1  \n",
       "4       0      1  \n",
       "6       0      1  \n",
       "8       0      1  \n",
       "10      0      1  \n",
       "11      0      1  \n",
       "16      0      1  \n",
       "19      0      1  \n",
       "20      0      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples of positive (=non-spam) samples, label id 0\n",
    "\n",
    "df_train.loc[df_train[\"label\"]==0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:09.259985Z",
     "start_time": "2023-09-29T07:07:09.196585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alessandro leite</td>\n",
       "      <td>2014-11-05T22:21:36</td>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salim Tayara</td>\n",
       "      <td>2014-11-02T14:33:30</td>\n",
       "      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Giang Nguyen</td>\n",
       "      <td>2014-11-06T04:55:41</td>\n",
       "      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Holly</td>\n",
       "      <td>2014-11-06T13:41:30</td>\n",
       "      <td>Follow me on Twitter @mscalifornia95﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iKap Taz</td>\n",
       "      <td>2014-11-08T13:34:27</td>\n",
       "      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Malin Linford</td>\n",
       "      <td>2014-11-05T01:13:43</td>\n",
       "      <td>Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lone Twistt</td>\n",
       "      <td>2013-11-28T17:34:55</td>\n",
       "      <td>Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Олег Пась</td>\n",
       "      <td>2014-11-03T23:29:00</td>\n",
       "      <td>Plizz withing my channel ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JD COKE</td>\n",
       "      <td>2014-11-08T02:24:02</td>\n",
       "      <td>It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rancy Gaming</td>\n",
       "      <td>2014-11-06T09:41:07</td>\n",
       "      <td>What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                 date  \\\n",
       "0   Alessandro leite  2014-11-05T22:21:36   \n",
       "1       Salim Tayara  2014-11-02T14:33:30   \n",
       "5       Giang Nguyen  2014-11-06T04:55:41   \n",
       "7              Holly  2014-11-06T13:41:30   \n",
       "9           iKap Taz  2014-11-08T13:34:27   \n",
       "12     Malin Linford  2014-11-05T01:13:43   \n",
       "13       Lone Twistt  2013-11-28T17:34:55   \n",
       "14         Олег Пась  2014-11-03T23:29:00   \n",
       "15           JD COKE  2014-11-08T02:24:02   \n",
       "17      Rancy Gaming  2014-11-06T09:41:07   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                          text  \\\n",
       "0                                                                                                                                                                                                                                                                                  pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n",
       "1                                                                                                                                                                                                                                                          if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n",
       "5                                                                                                                                                                                                                                                                                                                                          https://www.facebook.com/teeLaLaLa﻿   \n",
       "7                                                                                                                                                                                                                                                                                                                                        Follow me on Twitter @mscalifornia95﻿   \n",
       "9                                                                                                                                                                                                                                                                                                     Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n",
       "12                                                                                                                                                                                                                              Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿   \n",
       "13                                                                                                                                                                                          Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿   \n",
       "14                                                                                                                                                                                                                                                                                                                                                  Plizz withing my channel ﻿   \n",
       "15  It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿   \n",
       "17                                                                                                                                                                                                                                                                                             What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿   \n",
       "\n",
       "    label  video  \n",
       "0       1      1  \n",
       "1       1      1  \n",
       "5       1      1  \n",
       "7       1      1  \n",
       "9       1      1  \n",
       "12      1      1  \n",
       "13      1      1  \n",
       "14      1      1  \n",
       "15      1      1  \n",
       "17      1      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples of negative (=spam) samples, label id 0\n",
    "\n",
    "df_train.loc[df_train[\"label\"]==1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:10.071983Z",
     "start_time": "2023-09-29T07:07:10.000850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go here to check the views :3﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Came here to check the views, goodbye.﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am 2,126,492,636 viewer :D﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.facebook.com/teeLaLaLa﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Follow me on Twitter @mscalifornia95﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can we reach 3 billion views by December 2014? ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>On 0:02 u can see the camera man on his glasses....﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Plizz withing my channel ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i think about 100 millions of the views come from people who only wanted to  check the views﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.facebook.com/SchoolGeniusNITS/photos/ms.c.eJw9kVkOxDAMQm808h5z~;4sNjqP~_tHqBEuM69AQUp1Ih~_fPHgk5zLLsVdQv0ZUf0MB~;LnUJ~;ufTH4YoKfRxYts2zvrrp6qGtw67y~;L551h~;f7~_vlcZzRG8vGCTlPSD9ONGeWhj8~_GIbu~;S3lzMvY~;IQ2~;TwSfzz9WHn7JUSvHufpglQRZczl05fNPhaGeVb3x8yDmC6X~_~;jTcjnMho~;vfXWCjZyvWObihrnGx2ocjnG2PG1EvHXzyjD~_o3h~_RY6f57sPrnD2xV~;~_BzszZ~;8~-.bps.a.390875584405933/391725794320912/?type=1&amp;amp;theater ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What my gangnam style﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                   pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al﻿   \n",
       "1                                                                                                                                                                                                                                                                                                           if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.﻿   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                go here to check the views :3﻿   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                       Came here to check the views, goodbye.﻿   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                 i am 2,126,492,636 viewer :D﻿   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                           https://www.facebook.com/teeLaLaLa﻿   \n",
       "6                                                                                                                                                                                                                                                                                                                                           imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                         Follow me on Twitter @mscalifornia95﻿   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                              Can we reach 3 billion views by December 2014? ﻿   \n",
       "9                                                                                                                                                                                                                                                                                                                                                      Follow 4 Follow                           @ VaahidMustafic Like 4 Like ﻿   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                         On 0:02 u can see the camera man on his glasses....﻿   \n",
       "11                                                                                                                                                                                                                                                                                                                      2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name﻿   \n",
       "12                                                                                                                                                                                                                                                                               Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post﻿   \n",
       "13                                                                                                                                                                                                                                           Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.﻿   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                   Plizz withing my channel ﻿   \n",
       "15                                                   It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ ﻿   \n",
       "16                                                                                                                                                                                                                                                                                                                                i think about 100 millions of the views come from people who only wanted to  check the views﻿   \n",
       "17                                                                                                                                                                                                                                                                                                                                              What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194﻿   \n",
       "18  https://www.facebook.com/SchoolGeniusNITS/photos/ms.c.eJw9kVkOxDAMQm808h5z~;4sNjqP~_tHqBEuM69AQUp1Ih~_fPHgk5zLLsVdQv0ZUf0MB~;LnUJ~;ufTH4YoKfRxYts2zvrrp6qGtw67y~;L551h~;f7~_vlcZzRG8vGCTlPSD9ONGeWhj8~_GIbu~;S3lzMvY~;IQ2~;TwSfzz9WHn7JUSvHufpglQRZczl05fNPhaGeVb3x8yDmC6X~_~;jTcjnMho~;vfXWCjZyvWObihrnGx2ocjnG2PG1EvHXzyjD~_o3h~_RY6f57sPrnD2xV~;~_BzszZ~;8~-.bps.a.390875584405933/391725794320912/?type=1&amp;theater ﻿   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                       What my gangnam style﻿   \n",
       "\n",
       "    label  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       1  \n",
       "6       0  \n",
       "7       1  \n",
       "8       0  \n",
       "9       1  \n",
       "10      0  \n",
       "11      0  \n",
       "12      1  \n",
       "13      1  \n",
       "14      1  \n",
       "15      1  \n",
       "16      0  \n",
       "17      1  \n",
       "18      1  \n",
       "19      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"text\", \"label\"]][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to start weak supervision! So, let's imagin the gold labels disappeared... \n",
    "\n",
    "<img src=\"../img/poof.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here we are: there is some data we want to use for classifier training, but we don't have any labels and capacity/time/money/... for hiring annotators.\n",
    "\n",
    "But we can label this data with **weak supervision** :)\n",
    "\n",
    "<img src=\"../img/rainbow.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak Supervision\n",
    "\n",
    "A brief reminder how weak supervision works:\n",
    "1. We come up with some heuristic rules and transform these rules into labeling functions.\n",
    "2. We apply these labeling functions to the data and obtain weak labels.\n",
    "3. We use this weak labels to train a classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the training samples we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:11.829421Z",
     "start_time": "2023-09-29T07:07:11.769979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how is this shit still relevant \\ufeff',\n",
       " ' Hey everyone!! I have just started my first YT channel i would be grateful  if some of you peoples could check out my first clip in BF4! and give me  some advice on how my video was and how i could improve it. ALSO be sure to  go check out the about to see what Im all about. Thanks for your time :) .  and to haters... You Hate, I WIN\\ufeff',\n",
       " 'The Funny Thing Is That this song was made in 2009 but it took 2 years to  get to america.\\ufeff',\n",
       " 'Why dafuq is a Korean song so big in the USA. Does that mean we support  Koreans? Last time I checked they wanted to bomb us. \\ufeff',\n",
       " 'People Who Say That \"This Song Is Too Old Now, There\\'s No Point Of  Listening To It\" Suck. Just Stfu And Enjoy The Music. So, Your Mom Is Old  Too But You Still Listen To Her Right?....\\ufeff',\n",
       " 'Follow me on twitter &amp; IG : __killuminati94\\ufeff',\n",
       " 'how does this video have 2,127,322,484 views if there are only 7 million  people on earth?\\ufeff',\n",
       " 'Just coming to check if people are still viewing this video. And  apparently, they still do.\\ufeff',\n",
       " 'I wanted to know the name of the guy that dances at 00:58, anybody knows ?\\ufeff',\n",
       " 'hi guys please my android photo editor download. thanks https://play.google.com/store/apps/details?id=com.butalabs.photo.editor\\ufeff',\n",
       " 'Can anyone sub to my channel? :D\\ufeff',\n",
       " 'Hahah, juyk! I allways laugh at the part 1:57.. LOL!\\ufeff',\n",
       " \"Don't mind me, I'm just checking what the views are up to : )\\ufeff\",\n",
       " 'subscribe to my channel people :D\\ufeff',\n",
       " 'watch?v=vtaRGgvGtWQ   Check this out .\\ufeff',\n",
       " 'https://www.indiegogo.com/projects/cleaning-the-pan--2    please halp me  with my project\\ufeff',\n",
       " 'The girl in the train who was dancing, her outfit was so fucking sexy, but  the huge turn-off was she lacked eyebrows D:\\ufeff',\n",
       " 'sub me if you dont like the song\\ufeff',\n",
       " 'This video is so cool, again and again!\\ufeff',\n",
       " 'This has had over 2 billion views.  Holy shit.\\ufeff']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_train.text[100:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T21:04:15.013913Z",
     "start_time": "2023-08-09T21:04:15.007312Z"
    }
   },
   "source": [
    "## Task: formulate the rules that could annotate the training samples\n",
    "\n",
    "The questions that might help you: \n",
    "\n",
    "*What patterns are typical for spam YouTube comments? for non-spam comments?*\n",
    "\n",
    "*What rules might help to distinguish between spam and not-spam YouTube comments?*\n",
    "\n",
    "*What labeling functions do you think are productive and useful to annotate the YouTube comments?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules: \n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "4. ...\n",
    "5. ...\n",
    "6. ...\n",
    "7. ...\n",
    "8. ...\n",
    "9. ...\n",
    "10. ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My examples of rules: \n",
    "- \"check\"/\"check out\": if there is a collocation \"check out\" in the comment, most probably this comment is spam (and the comment author is promoting his/her channel)\n",
    "- \"subscribe\": same\n",
    "- \"my\": same\n",
    "- ...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can be a rule?\n",
    "\n",
    "- Keyword searches: looking for specific words in a sentence\n",
    "- Pattern matching: looking for specific syntactical patterns\n",
    "- Third-party models: using an pre-trained model (usually a model for a different task than the one at hand)\n",
    "- ...\n",
    "- Crowdworker labels: treating each crowdworker as a black-box function that assigns labels to subsets of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules into labeling functions\n",
    "\n",
    "After we collected some rules, we transform them into labeling functions that could *label* the data sample - that is, assign it to one or another class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:14.148640Z",
     "start_time": "2023-09-29T07:07:14.091820Z"
    }
   },
   "outputs": [],
   "source": [
    "# an example of LF based on a keyword \"check out\"\n",
    "\n",
    "def check_out(x):\n",
    "    return 1 if \"check out\" in x.text.lower() else -1\n",
    "\n",
    "# meaning the sample will be assigned to class 1 (=SPAM) if there is a \"check out\" expression in the comment, \n",
    "# otherwise to class 0 (=non-SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:14.758009Z",
     "start_time": "2023-09-29T07:07:14.706675Z"
    }
   },
   "outputs": [],
   "source": [
    "# an example of LF based on a key word \"please\"\n",
    "\n",
    "def check(x):\n",
    "    return 1 if \"please\" in x.text.lower() else -1\n",
    "\n",
    "# meaning the sample will be assigned to class 1 (=SPAM) if there is a \"please\" expression in the comment, \n",
    "# otherwise to class 0 (=non-SPAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T22:01:27.414881Z",
     "start_time": "2023-08-09T22:01:26.383285Z"
    }
   },
   "source": [
    "### Labeling functions we are going to use\n",
    "\n",
    "In this tutorial, we are going to use the labeling functions created by [Snorkel team](https://github.com/snorkel-team/snorkel-tutorials/blob/master/spam/01_spam_tutorial.ipynb), which are: \n",
    "\n",
    "\n",
    "1. keyword **\"my\"** (to detect spam comments like \"my channel\", \"my video\", etc)\n",
    "2. keyword **\"subscribe\"** (to detect spam comments that ask users to subscribe to some channel)\n",
    "3. keyword **\"http\"** (to detect spam comments that link to other channels)\n",
    "4. keyword **\"please\"/\"plz\"** (to detect spam comments that make requests rather than commenting)\n",
    "5. keyword **\"song\"** (to detect non-spam comments that actually talk about the video's content)\n",
    "6. regex **\"check_out\"** (to detect spam comments like \"check out this channel\", etc)\n",
    "7. **short comment** (non-spam comments are often short, such as 'cool video!')\n",
    "8. **mentioning specific people** and are **short** (using SpaCy library; non-spam comments usually mention some people)\n",
    "9. **polarity** (using TextBlob library; if polarity > 0.9, it is most probably a non-spam message)\n",
    "10. **subjectivity** (using TextBlob library; if subjectivity >= 0.5, it is most probably a non-spam message)\n",
    "\n",
    "(We are not going into details of the labeling process here now - you will hear more about it from my colleagues later). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed data\n",
    "\n",
    "The resulted annotations can be saved in the following format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:16.202276Z",
     "start_time": "2023-09-29T07:07:16.132891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n",
       " 'label': 1,\n",
       " 'weak_labels': [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/youtube/train.json\") as train_file:\n",
    "    train_data = json.load(train_file)\n",
    "train_data[\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T14:38:12.461055Z",
     "start_time": "2023-08-10T14:38:12.445819Z"
    }
   },
   "source": [
    "The structure of the processed data is the following: \n",
    "- data.text: the text of the sample\n",
    "- label: gold label obtained by manual annotation\n",
    "- weak_labels: the results of annotation by labeling functions. \n",
    "    - -1: the corresponding labeling function did not match\n",
    "    - 0: the labeling function matched and assigned this sample to class 0 (non-spam class in our case)\n",
    "    - 1: the labeling function matched and assigned this sample to class 1 (spam class in our case)\n",
    "\n",
    "So, for the sample #1:\n",
    "(*if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff*)\n",
    "\n",
    "- labeling functions 1, 3, 5, 6, 7, 8, 9 did not match\n",
    "- labeling functions 2 (a key word *subscribe*) & 4 (a key word *plz*) matched and assigned this sample to the class 1\n",
    "- labeling function 10 (subjectivity score > 0.5) matched and assigned this sample to the class 0\n",
    "\n",
    "**Next step: how to turn these annotations into weak labels to train a classifier with them?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:48:13.475728Z",
     "start_time": "2023-08-10T15:48:13.094259Z"
    }
   },
   "source": [
    "## Weak labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:48:15.062358Z",
     "start_time": "2023-08-10T15:48:15.049170Z"
    }
   },
   "source": [
    "There are different *label models* that calculate the weak labels based on labeling functions annotations. In this tutorial, we are going to try two of them: \n",
    "\n",
    "- **Majority Vote** (intuitive and straightforward)\n",
    "- **FABLE** [1] (most recent and well-performing)\n",
    "\n",
    "For label calculation and model training we will use a weakly supervised framework called [Wrench](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiRmYabjOGAAxW1h_0HHQt3COQQFnoECA4QAQ&url=https%3A%2F%2Fgithub.com%2FJieyuZ2%2Fwrench&usg=AOvVaw3EWVM0icLVHENbUv51USa_&opi=89978449) [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrench dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we transform our data into a Wrench-specific dataset.\n",
    "\n",
    "We can encode the data with TF-IDF features... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:19.233913Z",
     "start_time": "2023-09-29T07:07:18.855207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:18 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6c2851ff50477aa5a52009d576bb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:18 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159e463fcc714d00a910fdd1e19fb8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:19 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c146bc9a6ede446c9f91c8a00bc20a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF-IDF features\n",
    "\n",
    "from wrench.dataset import load_dataset\n",
    "\n",
    "train_data_tfidf, valid_data_tfidf, test_data_tfidf = load_dataset(\n",
    "    path_to_data,     # path to the folder where the dataset is stored\n",
    "    \"youtube\",         # name of the dataset\n",
    "    extract_feature=True,      # we want to encode out data ...\n",
    "    extract_fn='tfidf'        # ... with TF-IDF features (other predefined options are 'sentence_transformer', 'bert')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or with BERT features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:20.719875Z",
     "start_time": "2023-09-29T07:07:20.521959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:20 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10628bcc4844926b2eee82d23255c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:20 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbefa53d2a7a4270a9e3cec8719bad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:20 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a143cf7ae2f40da97705326dc800b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 07:07:20 - loading features from data/youtube/train_bert.pkl\n",
      "2023-09-29 07:07:20 - loading features from data/youtube/valid_bert.pkl\n",
      "2023-09-29 07:07:20 - loading features from data/youtube/test_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Bert features\n",
    "\n",
    "train_data, valid_data, test_data = load_dataset(\n",
    "    path_to_data,       # path to the folder where the dataset is stored\n",
    "    \"youtube\",    # name of the dataset\n",
    "    extract_feature=True,      # we want to encode out data ...\n",
    "    extract_fn='bert',        # ... with bert embeddings\n",
    "    model_name='bert-base-cased',      # the name of the bert model\n",
    "    cache_name='bert'     # load it from cache if there are cached files \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look what's inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:21.708025Z",
     "start_time": "2023-09-29T07:07:21.643760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wrench.dataset.dataset.TextDataset at 0x7f85107da670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the format of the train_data, valida_data, and test_data now is: wrench.dataset.dataset.TextDataset\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:22.570627Z",
     "start_time": "2023-09-29T07:07:22.512869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many classes are there in the dataset?\n",
    "\n",
    "train_data.n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:23.517965Z",
     "start_time": "2023-09-29T07:07:23.327186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many labeling functions are there in the dataset?\n",
    "\n",
    "train_data.n_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:23.716877Z",
     "start_time": "2023-09-29T07:07:23.555414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'HAM', 1: 'SPAM'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the class_id to class correspondence?\n",
    "\n",
    "train_data.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:24.217662Z",
     "start_time": "2023-09-29T07:07:24.151065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al\\ufeff'},\n",
       " {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n",
       " {'text': 'go here to check the views :3\\ufeff'},\n",
       " {'text': 'Came here to check the views, goodbye.\\ufeff'},\n",
       " {'text': 'i am 2,126,492,636 viewer :D\\ufeff'},\n",
       " {'text': 'https://www.facebook.com/teeLaLaLa\\ufeff'},\n",
       " {'text': 'imagine if this guy put adsense on with all these views... u could pay ur  morgage\\ufeff'},\n",
       " {'text': 'Follow me on Twitter @mscalifornia95\\ufeff'},\n",
       " {'text': 'Can we reach 3 billion views by December 2014? \\ufeff'},\n",
       " {'text': 'Follow 4 Follow                           @ VaahidMustafic Like 4 Like \\ufeff'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do the samples look like?\n",
    "\n",
    "train_data.examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:07:24.814743Z",
     "start_time": "2023-09-29T07:07:24.762610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7608848 ,  0.4292751 ,  0.99990165, ...,  0.99997175,\n",
       "        -0.7515034 ,  0.9910971 ],\n",
       "       [-0.7922811 ,  0.47435865,  0.9999021 , ...,  0.9999663 ,\n",
       "        -0.7555875 ,  0.9860616 ],\n",
       "       [-0.71461093,  0.4088342 ,  0.9997614 , ...,  0.9999327 ,\n",
       "        -0.5964781 ,  0.98014975],\n",
       "       ...,\n",
       "       [-0.7311086 ,  0.40834075,  0.9998686 , ...,  0.99996996,\n",
       "        -0.6895463 ,  0.9860986 ],\n",
       "       [-0.606766  ,  0.48277682,  0.99963987, ...,  0.9999085 ,\n",
       "        -0.89470583,  0.97945964],\n",
       "       [-0.7177589 ,  0.49044982,  0.9998655 , ...,  0.999958  ,\n",
       "        -0.82362586,  0.9884726 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do the encoded samples look like?\n",
    "\n",
    "print(type(train_data.features))\n",
    "train_data.features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:07:52.859104Z",
     "start_time": "2023-09-26T15:07:52.781222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the weak annotations produced by labeling functions?\n",
    "\n",
    "train_data.weak_labels[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T21:57:30.953595Z",
     "start_time": "2023-08-09T21:57:30.941063Z"
    }
   },
   "source": [
    "### Majority Vote\n",
    "\n",
    "The simplest and most straightforward method to calculate labels from the noisy annotations is **majority voting** - a decision-making method where the option with the most votes is chosen. It's like asking a group of people to pick a movie, and the one that gets the most hands raised wins. \n",
    "\n",
    "In our case, each labeling function produces a *vote*; the most voted class is selected as a sample label. All ties are broken randomly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:  write your own majority vote function\n",
    "- Input: the weak annotations produced by labeling functions (stored in weak_labels field of wrench dataset objects)\n",
    "- Output: labels\n",
    "\n",
    "Before you start programming, think about possible bottlenecks: \n",
    "- what if a sample obtains equal amount of votes for some class?\n",
    "- what if there are no votes for a sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:53:35.154155Z",
     "start_time": "2023-09-29T07:53:34.968948Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, 1, -1, -1, -1, 0, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.weak_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:53:38.091760Z",
     "start_time": "2023-09-29T07:53:37.945667Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "def majority_vote(weak_annotations):\n",
    "    # calculate labels with majority vote\n",
    "    # output should be a numpy array of shape (number of training samples) x 1\n",
    "    labels = []\n",
    "    # todo\n",
    "    return np.array(labels)\n",
    "\n",
    "labels_mv = majority_vote(train_data.weak_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ready solution to aggregate the weak labels with majority vote is already included to the Wrench framework:`MajorityVoting` label model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:53:47.805936Z",
     "start_time": "2023-09-29T07:53:47.690435Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize and fit the majority vote label model from the Wrench framework\n",
    "\n",
    "from wrench.labelmodel import MajorityVoting\n",
    "\n",
    "label_model = MajorityVoting()\n",
    "label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:53:51.662465Z",
     "start_time": "2023-09-29T07:53:51.529328Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate weak labels \n",
    "\n",
    "soft_label_mv = label_model.predict_proba(train_data)    # soft label as probabilities across all classes\n",
    "hard_label_mv = probs_to_preds(soft_label_mv)               # hard labels as the most probable classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T07:53:52.380816Z",
     "start_time": "2023-09-29T07:53:52.269947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_label_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 sentences, their weak annotations, and the weak labels obtained with majority voting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:24.167642Z",
     "start_time": "2023-09-26T15:08:24.112139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al\\ufeff'},\n",
       " {'text': 'if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\ufeff'},\n",
       " {'text': 'go here to check the views :3\\ufeff'},\n",
       " {'text': 'Came here to check the views, goodbye.\\ufeff'},\n",
       " {'text': 'i am 2,126,492,636 viewer :D\\ufeff'},\n",
       " {'text': 'https://www.facebook.com/teeLaLaLa\\ufeff'},\n",
       " {'text': 'imagine if this guy put adsense on with all these views... u could pay ur  morgage\\ufeff'},\n",
       " {'text': 'Follow me on Twitter @mscalifornia95\\ufeff'},\n",
       " {'text': 'Can we reach 3 billion views by December 2014? \\ufeff'},\n",
       " {'text': 'Follow 4 Follow                           @ VaahidMustafic Like 4 Like \\ufeff'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:27.263925Z",
     "start_time": "2023-09-26T15:08:27.207178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, 1, -1, -1, -1, 0, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.weak_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:29.585852Z",
     "start_time": "2023-09-26T15:08:29.447845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_label_mv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:08:32.403012Z",
     "start_time": "2023-09-26T15:08:32.344713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_label_mv[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FABLE \n",
    "\n",
    "Fable [1] is a label model where noisy labels are inferred not only based on the labeling functions' votes, but also using the instance features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:06.230196Z",
     "start_time": "2023-09-26T15:10:02.434766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values included: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                             | 2/1000 [00:18<2:36:20,  9.40s/iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize and apply the fable model\n",
    "from wrench.labelmodel import Fable\n",
    "\n",
    "label_model = Fable(kernel_function=None, num_groups=10)\n",
    "_ = label_model.fit(dataset_train=train_data, dataset_valid=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:13.120855Z",
     "start_time": "2023-09-26T15:10:09.497628Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                             | 2/1000 [00:18<2:32:54,  9.19s/iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate labels\n",
    "soft_label_fable = label_model.predict_proba(train_data)\n",
    "hard_label_fable = probs_to_preds(soft_label_fable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:16.193173Z",
     "start_time": "2023-09-26T15:10:16.134392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54772653, 0.45227347],\n",
       "       [0.04384498, 0.95615502],\n",
       "       [0.56616534, 0.43383466],\n",
       "       [0.55068925, 0.44931075],\n",
       "       [0.55410647, 0.44589353],\n",
       "       [0.87257854, 0.12742146],\n",
       "       [0.53917847, 0.46082153],\n",
       "       [0.5582726 , 0.4417274 ],\n",
       "       [0.51587386, 0.48412614],\n",
       "       [0.54213748, 0.45786252]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_label_fable[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:18.034452Z",
     "start_time": "2023-09-26T15:10:17.979782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_label_fable[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:20.555067Z",
     "start_time": "2023-09-26T15:10:20.490550Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with majorty vote hard labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:27.927925Z",
     "start_time": "2023-09-26T15:10:22.078808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# initialize a classifier\n",
    "model = EndClassifierModel(\n",
    "    batch_size=batch_size, test_batch_size=test_batch_size\n",
    ")\n",
    "\n",
    "# fit it on the training data + majority vote hard labels\n",
    "model.fit(\n",
    "    dataset_train=train_data, \n",
    "    y_train=hard_label_mv, \n",
    "    dataset_valid=valid_data, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# test on the test set\n",
    "model.test(dataset=test_data, metric_fn=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with FABLE hard labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:10:32.400286Z",
     "start_time": "2023-09-26T15:10:27.930583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# initialize a classifier\n",
    "model = EndClassifierModel(\n",
    "    batch_size=batch_size, test_batch_size=test_batch_size\n",
    ")\n",
    "\n",
    "# fit it \n",
    "model.fit(\n",
    "    dataset_train=train_data, \n",
    "    y_train=hard_label_fable, \n",
    "    dataset_valid=valid_data,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# test on the test set\n",
    "model.test(dataset=test_data, metric_fn=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-2-End training with SepLL\n",
    "\n",
    "In the following, we use a state-of-the-art method called SepLL [4] to train a classifier with weak labels. During training, LF matches are the only training signal, and prediction is then later made from a latent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T15:12:00.176454Z",
     "start_time": "2023-09-26T15:11:29.522834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 23:35:08 - \n",
      "==========[hyper parameters]==========\n",
      "{\n",
      "    \"batch_size\": 32,\n",
      "    \"real_batch_size\": 16,\n",
      "    \"test_batch_size\": 32,\n",
      "    \"n_steps\": 10000,\n",
      "    \"grad_norm\": -1,\n",
      "    \"use_lr_scheduler\": false,\n",
      "    \"binary_mode\": false\n",
      "}\n",
      "==========[optimizer config]==========\n",
      "{\n",
      "    \"name\": \"Adam\",\n",
      "    \"paras\": {\n",
      "        \"lr\": 0.001,\n",
      "        \"weight_decay\": 0.0\n",
      "    }\n",
      "}\n",
      "==========[backbone config]==========\n",
      "{\n",
      "    \"name\": \"MLP\",\n",
      "    \"paras\": {\n",
      "        \"hidden_size\": 100,\n",
      "        \"dropout\": 0.0,\n",
      "        \"model_name\": \"roberta-base\"\n",
      "    }\n",
      "}\n",
      "==========[label model_config config]==========\n",
      "{\n",
      "    \"name\": \"MajorityVoting\",\n",
      "    \"paras\": {}\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../wrench/dataset/utils.py:43: UserWarning: No unlabeled data found! Use full dataset us unlabeled dataset\n",
      "  warnings.warn('No unlabeled data found! Use full dataset us unlabeled dataset')\n",
      "../wrench/classification/sepll.py:239: RuntimeWarning: invalid value encountered in divide\n",
      "  labeled_dataset.weak_labels / labeled_dataset.weak_labels.sum(axis=1, keepdims=True)\n",
      "../wrench/classification/sepll.py:243: RuntimeWarning: invalid value encountered in divide\n",
      "  dataset_valid.weak_labels / dataset_valid.weak_labels.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f074109e7b4ae482d41a497c69cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRAIN] SepLL:   0%|                                                                                          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 23:35:38 - [INFO] early stop @ step 3000!\n",
      "2023-09-28 23:35:38 - SepLL test acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "from wrench.classification.sepll import SepLL\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "bert_model_name = 'roberta-base'\n",
    "\n",
    "#### Initialize SepLL\n",
    "model = SepLL(\n",
    "    batch_size=batch_size,\n",
    "    test_batch_size=test_batch_size,\n",
    "    backbone='MLP',\n",
    "    backbone_model_name=bert_model_name,\n",
    "    # \n",
    "    # SepLL specific\n",
    "    add_unlabeled=False,\n",
    "    class_noise=0.0,\n",
    "    lf_l2_regularization=0.05,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    dataset_train=train_data,\n",
    "    dataset_valid=valid_data,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "acc = model.test(test_data, 'acc')\n",
    "\n",
    "logger.info(f'SepLL test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### GPU training\n",
    "\n",
    "In case your environment has a GPU available, it is also possible to make use of the full strength of SepLL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 23:35:41 - \n",
      "==========[hyper parameters]==========\n",
      "{\n",
      "    \"batch_size\": 16,\n",
      "    \"real_batch_size\": 16,\n",
      "    \"test_batch_size\": 32,\n",
      "    \"n_steps\": 10000,\n",
      "    \"grad_norm\": -1,\n",
      "    \"use_lr_scheduler\": false,\n",
      "    \"binary_mode\": false\n",
      "}\n",
      "==========[optimizer config]==========\n",
      "{\n",
      "    \"name\": \"Adam\",\n",
      "    \"paras\": {\n",
      "        \"lr\": 5e-05,\n",
      "        \"weight_decay\": 0.0\n",
      "    }\n",
      "}\n",
      "==========[backbone config]==========\n",
      "{\n",
      "    \"name\": \"BERT\",\n",
      "    \"paras\": {\n",
      "        \"model_name\": \"roberta-base\",\n",
      "        \"max_tokens\": 512,\n",
      "        \"fine_tune_layers\": -1\n",
      "    }\n",
      "}\n",
      "==========[label model_config config]==========\n",
      "{\n",
      "    \"name\": \"MajorityVoting\",\n",
      "    \"paras\": {}\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../wrench/dataset/utils.py:43: UserWarning: No unlabeled data found! Use full dataset us unlabeled dataset\n",
      "  warnings.warn('No unlabeled data found! Use full dataset us unlabeled dataset')\n",
      "../wrench/classification/sepll.py:239: RuntimeWarning: invalid value encountered in divide\n",
      "  labeled_dataset.weak_labels / labeled_dataset.weak_labels.sum(axis=1, keepdims=True)\n",
      "../wrench/classification/sepll.py:243: RuntimeWarning: invalid value encountered in divide\n",
      "  dataset_valid.weak_labels / dataset_valid.weak_labels.sum(axis=1, keepdims=True)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9e86c63f264d5c942dc4095dc3995c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRAIN] SepLL:   0%|                                                                                          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 23:41:52 - KeyboardInterrupt! do not terminate the process in case need to save the best model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 27\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#### Initialize SepLL\u001B[39;00m\n\u001B[1;32m      9\u001B[0m model \u001B[38;5;241m=\u001B[39m SepLL(\n\u001B[1;32m     10\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m     11\u001B[0m     real_batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     lf_l2_regularization\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m,\n\u001B[1;32m     24\u001B[0m )\n\u001B[0;32m---> 27\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_valid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43macc\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     32\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/WS_tutorial/wrench/classification/sepll.py:349\u001B[0m, in \u001B[0;36mSepLL.fit\u001B[0;34m(self, dataset_train, dataset_valid, y_valid, cut_tied, valid_mode, evaluation_step, metric, direction, patience, tolerance, device, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m    347\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKeyboardInterrupt! do not terminate the process in case need to save the best model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 349\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_finalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[0;32m~/PycharmProjects/WS_tutorial/wrench/basemodel.py:218\u001B[0m, in \u001B[0;36mBaseTorchModel._finalize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_finalize\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalid_flag:\n\u001B[0;32m--> 218\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_model\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalid_dataloader\n",
      "File \u001B[0;32m~/PycharmProjects/WS_tutorial/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1379\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;66;03m# copy state_dict so _load_from_state_dict can modify it\u001B[39;00m\n\u001B[1;32m   1378\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(state_dict, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1379\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m \u001B[43mstate_dict\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m()\n\u001B[1;32m   1380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1381\u001B[0m     \u001B[38;5;66;03m# mypy isn't aware that \"_metadata\" exists in state_dict\u001B[39;00m\n\u001B[1;32m   1382\u001B[0m     state_dict\u001B[38;5;241m.\u001B[39m_metadata \u001B[38;5;241m=\u001B[39m metadata  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from wrench.classification.sepll import SepLL\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "batch_size=16\n",
    "bert_model_name = 'roberta-base'\n",
    "\n",
    "#### Initialize SepLL\n",
    "model = SepLL(\n",
    "    batch_size=batch_size,\n",
    "    real_batch_size=batch_size,\n",
    "    test_batch_size=test_batch_size,\n",
    "    # BERT specific parameters\n",
    "    backbone='BERT',\n",
    "    backbone_model_name=bert_model_name,\n",
    "    optimizer='Adam',\n",
    "    optimizer_lr=5e-5,\n",
    "    optimizer_weight_decay=0.0,\n",
    "    \n",
    "    # SepLL specific\n",
    "    add_unlabeled=False,\n",
    "    class_noise=0.0,\n",
    "    lf_l2_regularization=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    dataset_train=train_data,\n",
    "    dataset_valid=valid_data,\n",
    "    metric='acc',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acc = model.test(test_data, 'acc')\n",
    "\n",
    "logger.info(f'SepLL test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Zhang et al. 2023. Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision. https://arxiv.org/abs/2210.02724 \n",
    "2. Zhang et al. 2021 WRENCH: A Comprehensive Benchmark for Weak Supervision. https://arxiv.org/abs/2109.11377\n",
    "3. Alberto TC et al.  2015. Tubespam: Comment Spam Filtering on Youtube. https://ieeexplore.ieee.org/document/7424299\n",
    "4. Stephan et al. 2022. SepLL: Separating Latent Class Labels from Weak Supervision Noise. https://arxiv.org/abs/2210.13898\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-tutorial",
   "language": "python",
   "name": "ws-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
