{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import skweak\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.taggers import PatternTagger\n",
    "\n",
    "from scripts.skweak_ner_eval import evaluate\n",
    "from scripts.utils import penntreebank2universal, load_data_split, tag_all, compute_recall, compute_num_conflicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c6764-fbd0-4de2-9834-d8f7ac23401f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c82819010da668",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using Libraries as Labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77005834bde48ac8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "In this part, we use popular NLP libraries to create labeling functions. They include Spacy, NLTK, Textblob.\n",
    "We use the Majority Voter and HMM as aggregation functions\n",
    "Optionally, you can train your own model on the data.\n",
    "\n",
    "Learning goals:\n",
    "- Understand how to use external libraries as labeling functions\n",
    "- Understand the Spacy object and how to use it for annotation\n",
    "- Understand the impact of Majority Voter and HMM as aggregation functions, and get a feeling for their performance\n",
    "\n",
    "First, read and understand the two functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d07962ce9132e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sometimes data formats (here POS tags) differ. We load the data and convert it to the format we need. \n",
    "# Surely, there is some loss of information\n",
    "def nltk_tagger(doc):\n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            # Tag token with nltk\n",
    "            nltk_pos = nltk.pos_tag([token.text])[0][1]\n",
    "            # Map nltk pos tags to ours\n",
    "            if nltk_pos == \"DT\":\n",
    "                yield token.i, token.i + 1, \"DET\"\n",
    "            elif nltk_pos == \"CD\":\n",
    "                yield token.i, token.i + 1, \"NUM\"\n",
    "            elif nltk_pos == \"NNP\" or nltk_pos == \"NNPS\":\n",
    "                yield token.i, token.i + 1, \"PROPN\"\n",
    "            elif nltk_pos == \"JJ\" or nltk_pos == \"JJR\" or nltk_pos == \"JJS\":\n",
    "                yield token.i, token.i + 1, \"ADJ\"\n",
    "            elif nltk_pos == \"NN\" or nltk_pos == \"NNS\":\n",
    "                yield token.i, token.i + 1, \"NOUN\"\n",
    "            elif nltk_pos == \"VB\" or nltk_pos == \"VBD\" or nltk_pos == \"VBG\" or nltk_pos == \"VBN\" or nltk_pos == \"VBP\" or nltk_pos == \"VBZ\":\n",
    "                yield token.i, token.i + 1, \"VERB\"\n",
    "\n",
    "\n",
    "# We cn also use the Textblob library to get POS tags\n",
    "# Under the hood, it uses the Pattern library. Once again, a transformation of the tag-labels is needed\n",
    "def textblob_tagger(doc):\n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            textblob_pos = TextBlob(token.text, pos_tagger=PatternTagger()).tags\n",
    "            if len(textblob_pos) > 0:\n",
    "                yield token.i, token.i + 1, penntreebank2universal(textblob_pos[0][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4348a2397f6a49",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Write the Spacy Labeling Functions\n",
    "\n",
    "Use the two english Spacy models \"en_core_web_sm\", \"en_core_web_md\" to create labeling functions.\n",
    "The challenge is that they use different tokens, i.e. the atomic units of a sentence. Our simple tokenization just splits the words by whitespace.\n",
    "Your task it to design an algorithm that maps the tokens of the simple tokenization to the tokens of the Spacy tokenization, and use the token available there to create labeling functions.\n",
    "\n",
    "Hints:\n",
    "1) Access token i by `token=doc[i]` or obtain its poition by `i=token.i`\n",
    "2) Access the Spacy POS token (its ground truth) by `pos=token.pos_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cb7b0baabc0dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng_nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "eng_nlp_md = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def eng_spacy_tagger_sm(doc):\n",
    "    other_doc = eng_nlp_sm(doc.text)\n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "\n",
    "\n",
    "def eng_spacy_tagger_md(doc):\n",
    "    other_doc = eng_nlp_md(doc.text)\n",
    "\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f68796512fc640",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nltk_lf = skweak.heuristics.FunctionAnnotator(\"nltk\", nltk_tagger)\n",
    "textblob_lf = skweak.heuristics.FunctionAnnotator(\"textblob\", textblob_tagger)\n",
    "eng_spacy_sm_lf = skweak.heuristics.FunctionAnnotator(\"eng_spacy_sm\", eng_spacy_tagger_sm)\n",
    "eng_spacy_md_lf = skweak.heuristics.FunctionAnnotator(\"eng_spacy_md\", eng_spacy_tagger_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8b210e20343af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load Data and apply Labeling functions\n",
    "\n",
    "Before and after applying the labeling functions, and the aggregation functions, we compute the recall and number of conflicts. For the sake of time, we use this time only a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ec18fe8aaaa40",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# load training and test data\n",
    "lfs = [nltk_lf, eng_spacy_sm_lf, textblob_lf, eng_spacy_md_lf]\n",
    "all_labels = [\"DET\", \"NUM\", \"PROPN\", \"NOUN\", \"ADJ\"]\n",
    "\n",
    "# small amount of data for the sake of time\n",
    "train_docs = load_data_split(\"train\", all_labels, 3000)\n",
    "\n",
    "# tag the training documents\n",
    "train_docs = tag_all(train_docs, lfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall = compute_recall(train_docs)\n",
    "num_conflicts = compute_num_conflicts(train_docs)\n",
    "print(\"Train recall\", recall)\n",
    "print(\"Train conflicts\", num_conflicts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b16efb06838904a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the recall is not very high. This is because the libraries are working quite well. \n",
    "Further, we observe that in 40.5% of the tokens there is a conflict."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8cf782f95a60db9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08f3ed08cedf82",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the HMM\n",
    "hmm = skweak.aggregation.HMM(\"hmm\", all_labels)\n",
    "hmm=hmm.fit(train_docs)\n",
    "\n",
    "# tag the test documents\n",
    "# it's important to set Majority vote before HMM, otherwise Majority Vote takes the HMM predictions into account"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we compare how majority vote and HMM change the number of conflicts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e621666dfaf0b2d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mv = skweak.aggregation.MajorityVoter(\"mv\", all_labels)\n",
    "train_docs = tag_all(train_docs, [mv, hmm])\n",
    "\n",
    "num_conflicts = compute_num_conflicts(train_docs)\n",
    "print(\"Conflicts with MV on train set: \", num_conflicts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e676268ebadf23d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the number of token conflicts does not change. The reason is that both methods can not choose a class different from the labeling functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b6d77c3573dcd8"
  },
  {
   "cell_type": "markdown",
   "id": "f1dd12ea303ccb36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Look at the Precision, Recall and F1-Score of the different aggregation functions. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b49144729e84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tag the test documents\n",
    "# it's important to set Majority vote before HMM, otherwise Majority Vote takes the HMM predictions into account\n",
    "test_docs = load_data_split(\"test\", all_labels, 1000)\n",
    "test_docs = tag_all(test_docs, lfs + [mv, hmm])\n",
    "\n",
    "num_conflicts = compute_num_conflicts(test_docs)\n",
    "print(\"Conflicts on test set\", num_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cc2af3f299780",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = evaluate(test_docs, all_labels, [ \"mv\", \"hmm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348319704d33552a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contrary, to the first part, we observe that the HMM performs better than majority vote."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "473cdfe8718e1ffd"
  },
  {
   "cell_type": "markdown",
   "id": "54b53ffadb0bc88b",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
